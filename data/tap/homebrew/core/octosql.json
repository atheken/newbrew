{
  "name": "octosql",
  "full_name": "octosql",
  "tap": "homebrew/core",
  "oldname": null,
  "oldnames": [],
  "aliases": [],
  "versioned_formulae": [],
  "desc": "SQL query tool to analyze data from different file formats and databases",
  "license": "MPL-2.0",
  "homepage": "https://github.com/cube2222/octosql/",
  "versions": {
    "stable": "0.12.2",
    "head": "HEAD",
    "bottle": true
  },
  "urls": {
    "stable": {
      "url": "https://github.com/cube2222/octosql/archive/refs/tags/v0.12.2.tar.gz",
      "tag": null,
      "revision": null,
      "checksum": "e2bf45a039d1f6bedfd900b656a42ee3986c5a27ddae1a083f2dc52011c3b401"
    },
    "head": {
      "url": "https://github.com/cube2222/octosql.git",
      "branch": "main"
    }
  },
  "revision": 0,
  "version_scheme": 0,
  "bottle": {
    "stable": {
      "rebuild": 0,
      "root_url": "https://ghcr.io/v2/homebrew/core",
      "files": {
        "arm64_ventura": {
          "cellar": ":any_skip_relocation",
          "url": "https://ghcr.io/v2/homebrew/core/octosql/blobs/sha256:ab15fc0d6bd735e1759005897c937cb8ba810793d1508224923404319f8b1e12",
          "sha256": "ab15fc0d6bd735e1759005897c937cb8ba810793d1508224923404319f8b1e12"
        },
        "arm64_monterey": {
          "cellar": ":any_skip_relocation",
          "url": "https://ghcr.io/v2/homebrew/core/octosql/blobs/sha256:ab15fc0d6bd735e1759005897c937cb8ba810793d1508224923404319f8b1e12",
          "sha256": "ab15fc0d6bd735e1759005897c937cb8ba810793d1508224923404319f8b1e12"
        },
        "arm64_big_sur": {
          "cellar": ":any_skip_relocation",
          "url": "https://ghcr.io/v2/homebrew/core/octosql/blobs/sha256:ab15fc0d6bd735e1759005897c937cb8ba810793d1508224923404319f8b1e12",
          "sha256": "ab15fc0d6bd735e1759005897c937cb8ba810793d1508224923404319f8b1e12"
        },
        "ventura": {
          "cellar": ":any_skip_relocation",
          "url": "https://ghcr.io/v2/homebrew/core/octosql/blobs/sha256:588d02eba041ad5bfbd774d3fb490cd5994e0b85aab64921dc048d53f1eb8705",
          "sha256": "588d02eba041ad5bfbd774d3fb490cd5994e0b85aab64921dc048d53f1eb8705"
        },
        "monterey": {
          "cellar": ":any_skip_relocation",
          "url": "https://ghcr.io/v2/homebrew/core/octosql/blobs/sha256:588d02eba041ad5bfbd774d3fb490cd5994e0b85aab64921dc048d53f1eb8705",
          "sha256": "588d02eba041ad5bfbd774d3fb490cd5994e0b85aab64921dc048d53f1eb8705"
        },
        "big_sur": {
          "cellar": ":any_skip_relocation",
          "url": "https://ghcr.io/v2/homebrew/core/octosql/blobs/sha256:588d02eba041ad5bfbd774d3fb490cd5994e0b85aab64921dc048d53f1eb8705",
          "sha256": "588d02eba041ad5bfbd774d3fb490cd5994e0b85aab64921dc048d53f1eb8705"
        },
        "x86_64_linux": {
          "cellar": ":any_skip_relocation",
          "url": "https://ghcr.io/v2/homebrew/core/octosql/blobs/sha256:2cd6c3302ec6f8a7ef8ce30631b3bc03969c8a63f5b5c7412d33b6f8c73f2f7c",
          "sha256": "2cd6c3302ec6f8a7ef8ce30631b3bc03969c8a63f5b5c7412d33b6f8c73f2f7c"
        }
      }
    }
  },
  "keg_only": false,
  "keg_only_reason": null,
  "options": [],
  "build_dependencies": [
    "go"
  ],
  "dependencies": [],
  "test_dependencies": [],
  "recommended_dependencies": [],
  "optional_dependencies": [],
  "uses_from_macos": [],
  "uses_from_macos_bounds": [],
  "requirements": [],
  "conflicts_with": [],
  "conflicts_with_reasons": [],
  "link_overwrite": [],
  "caveats": null,
  "installed": [],
  "linked_keg": null,
  "pinned": false,
  "outdated": false,
  "deprecated": false,
  "deprecation_date": null,
  "deprecation_reason": null,
  "disabled": false,
  "disable_date": null,
  "disable_reason": null,
  "post_install_defined": false,
  "service": null,
  "tap_git_head": "4eeae4ea50839e967536ba646d5e0ed6fbcbad7f",
  "ruby_source_path": "Formula/octosql.rb",
  "ruby_source_checksum": {
    "sha256": "3617bdb73a8fd9a12e7c379775db1311303bd8fa91de596185fc261084a0e9e3"
  },
  "date_added": "2022-05-17T18:55:38+00:00",
  "readme": "<img src=\"https://raw.githubusercontent.com/cube2222/octosql/main/images/logo.png\" width=\"168\">OctoSQL\n=======\n\nOctoSQL is predominantly a CLI tool which lets you query a plethora of databases and file formats using SQL through a unified interface, even do JOINs between them. (Ever needed to join a JSON file with a PostgreSQL table? OctoSQL can help you with that.)\n\nAt the same time it's an easily extensible full-blown dataflow engine, and you can use it to add a SQL interface to your own applications.\n\n[![GitHub](https://shields.io/github/actions/workflow/status/cube2222/octosql/test.yml?branch=main)](https://github.com/cube2222/octosql/actions/workflows/test.yml?query=branch%3Amain)\n[![Go Report Card](https://goreportcard.com/badge/github.com/cube2222/octosql)](https://goreportcard.com/report/github.com/cube2222/octosql)\n[![GoDoc](https://godoc.org/github.com/cube2222/octosql?status.svg)](https://godoc.org/github.com/cube2222/octosql)\n[![License](https://shields.io/github/license/cube2222/octosql)](LICENSE)\n[![Latest Version](https://shields.io/github/v/release/cube2222/octosql?display_name=tag&sort=semver)](https://github.com/cube2222/octosql/releases)\n[![Gitter](https://badges.gitter.im/octosql/general.svg)](https://gitter.im/octosql/general?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)\n\n![Demo](images/octosql-demo.gif)\n\n## Usage\n\n```bash\noctosql \"SELECT * FROM ./myfile.json\"\noctosql \"SELECT * FROM ./myfile.json\" --describe  # Show the schema of the file.\noctosql \"SELECT invoices.id, address, amount\n         FROM invoices.csv JOIN db.customers ON invoices.customer_id = customers.id\n         ORDER BY amount DESC\"\noctosql \"SELECT customer_id, SUM(amount)\n         FROM invoices.csv\n         GROUP BY customer_id\"\n```\n\nOctoSQL supports a [bunch of file formats](#File-Access) out of the box, but you can additionally install plugins to add support for other databases.\n```bash\noctosql \"SELECT * FROM plugins.available_plugins\"\noctosql plugin install postgres\necho \"databases:\n  - name: mydb\n    type: postgres\n    config:\n      host: localhost\n      port: 5443\n      database: mydb\n      user: postgres\n      password: postgres\" > octosql.yml\noctosql \"SELECT * FROM mydb.users\" --describe\noctosql \"SELECT * FROM mydb.users\"\n```\n\nYou can specify the output format using the `--output` flag. Available values for it are `live_table`, `batch_table`, `csv` and `stream_native`.\n\nThe documentation about available aggregates and functions is contained within OctoSQL itself. It's in the `aggregates`, `aggregate_signatures`, `functions` and `function_signatures` tables in the `docs` database.\n```bash\noctosql \"SELECT * FROM docs.functions fs\"\n+------------------+----------------------------------------+\n|     fs.name      |             fs.description             |\n+------------------+----------------------------------------+\n| 'abs'            | 'Returns absolute value                |\n|                  | of argument.'                          |\n| 'ceil'           | 'Returns ceiling of                    |\n|                  | argument.'                             |\n| ...              | ...                                    |\n+------------------+----------------------------------------+\n```\n\n## Installation\n\n### Homebrew\n\nYou can install OctoSQL using Homebrew on MacOS or Linux:\n```bash\nbrew install cube2222/octosql/octosql\n```\nAfter running it for the first time on MacOS you'll have to go into Preferences -> Security and Privacy -> Allow OctoSQL, as with any app that's not notarized.\n\n### Pre-Compiled binary\n\nYou can also download the binary for your operating system directly from the [Releases page](https://github.com/cube2222/octosql/releases).\n\n### Nix Package\n\nThe package can be installed in the local nix-profile.\n\n```shell\nnix-env -iA nixpkgs.octosql\n```\n\nFor adhoc or testing purposes a shell with the package can be spawned.\n\n```shell\nnix-shell -p octosql\n```\n\nFor NixOS users it is highly recommended to install the package by adding it to the list of `systemPackages`.\n\n```nix\nenvironment.systemPackages = with pkgs; [\n  octosql\n  # ...\n];\n```\n\n### Building from source\n\nWith Go in version >= 1.18 the application can be built from source.\nThis can be achieved by cloning the repository and running `go install` from the project directory.\n\n```shell\ngit clone https://github.com/cube2222/octosql\ncd octosql\ngo install\n```\n\n## File Access\n\nSupport for multiple file types is included by default in OctoSQL:\n- JSON (in JSONLines format, one object per line)\n- CSV\n- TSV\n- Parquet\n- Lines (reading a file line by line)\n\nIf your file has a matching extension, you can use its path directly as a table:\n```\n~> octosql \"SELECT * FROM my/file/path.json\"\n```\nor, if the extension is not right, you can use this alternative notation, where the extension is used in place of the database name:\n```\n~> octosql \"SELECT * FROM `json.my/file/path.whatever`\"\n```\n\nYou can also specify additional options using the following notation: `myfile.ext?key=value&key2=value2`\n\nThe following options are available:\n- CSV\n  - header: true/false (default: true) - Whether the file has a header row.\n- JSON\n  - tail: true/false (default: false) - Whether to keep waiting for new content after reaching the end of the file.\n- Lines\n  - tail: true/false (default: false) - Whether to keep waiting for new content after reaching the end of the file.\n\n### Reading from Standard Input\nYou can also pipe data in through stdin, and OctoSQL will expose it as the `stdin.<file_type>` table. For example:\n```\n~> echo '{\"hello\": \"world\"}' | octosql \"SELECT * FROM stdin.json\"\n+---------+\n|  hello  |\n+---------+\n| 'world' |\n+---------+\n~> seq 100 | octosql \"SELECT SUM(int(text)) FROM stdin.lines\"\n+------+\n| sum  |\n+------+\n| 5050 |\n+------+\n```\n\n## Plugins\n\nTo use databases which are not included in the core of OctoSQL - like PostgreSQL or MySQL - you need to install a plugin. Installing plugins is very easy. The following command installs the latest version of the PostgreSQL plugin:\n```bash\noctosql plugin install postgres\n```\nPlugins are grouped into repositories, and potentially have many versions available. The above uses the default **core** repository and tries to install the latest version. So if 0.42.0 was the latest version, the above would be equivalent to:\n```bash\noctosql plugin install core/postgres@0.42.0\n```\n\nBrowsing available and installed plugins is possible through OctoSQL itself, behind a SQL interface. The available tables are: `plugins.repositories`, `plugins.available_plugins`, `plugins.available_versions`, `plugins.installed_plugins`, `plugins.installed_versions`.\n\n```bash\n~> octosql \"SELECT name, description FROM plugins.available_plugins LIMIT 2\"\n+------------------------+-------------------------------+\n| available_plugins.name | available_plugins.description |\n+------------------------+-------------------------------+\n| 'postgres'             | 'Adds support for             |\n|                        | querying PostgreSQL           |\n|                        | databases.'                   |\n| 'random_data'          | 'Generates random data        |\n|                        | for testing.'                 |\n+------------------------+-------------------------------+\n~> octosql \"SELECT plugin_name, version FROM plugins.available_versions WHERE plugin_name='random_data'\"\n+--------------------------------+----------------------------+\n| available_versions.plugin_name | available_versions.version |\n+--------------------------------+----------------------------+\n| 'random_data'                  | '0.1.0'                    |\n| 'random_data'                  | '0.1.1'                    |\n| 'random_data'                  | '0.2.0'                    |\n+--------------------------------+----------------------------+\n```\n\nSome plugins, like the `random_data` plugin, can be used without any additional configuration:\n```bash\n~> octosql plugin install random_data\nDownloading core/random_data@0.2.0...\n~> octosql \"SELECT * FROM random_data.users\" --describe\n+---------------------------------+--------------------------+------------+\n|              name               |           type           | time_field |\n+---------------------------------+--------------------------+------------+\n| 'users.avatar'                  | 'String'                 | false      |\n| 'users.credit_card'             | '{cc_number: String}'    | false      |\n| 'users.date_of_birth'           | 'String'                 | false      |\n| 'users.email'                   | 'String'                 | false      |\n| 'users.first_name'              | 'String'                 | false      |\n| 'users.last_name'               | 'String'                 | false      |\n| ...                             | ...                      | ...        |\n+---------------------------------+--------------------------+------------+\n~> octosql \"SELECT first_name, last_name, date_of_birth FROM random_data.users LIMIT 3\"\n+------------------+-----------------+---------------------+\n| users.first_name | users.last_name | users.date_of_birth |\n+------------------+-----------------+---------------------+\n| 'Alethea'        | 'Kuvalis'       | '1997-01-07'        |\n| 'Ambrose'        | 'Spencer'       | '1979-04-18'        |\n| 'Antione'        | 'Hodkiewicz'    | '1980-03-04'        |\n+------------------+-----------------+---------------------+\n```\n\nOthers, like the `postgres` plugin, require additional configuration. The configuration file is located at `~/.octosql/octosql.yml`. You can find the available configuration settings for a plugin in its own documentation.\n```bash\n~> octosql plugin install postgres\nDownloading core/postgres@0.1.0...\necho \"databases:\n  - name: mydb\n    type: postgres\n    config:\n      host: localhost\n      port: 5432\n      database: postgres\n      user: postgres\n      password: mypassword\" > ~/.octosql/octosql.yml\n~> octosql \"SELECT * FROM mydb.customers\" --describe\n+--------------------------+-----------------+------------+\n|           name           |      type       | time_field |\n+--------------------------+-----------------+------------+\n| 'customers.email'        | 'String'        | false      |\n| 'customers.first_name'   | 'String'        | false      |\n| 'customers.id'           | 'Int'           | false      |\n| 'customers.last_name'    | 'String'        | false      |\n| 'customers.phone_number' | 'String | NULL' | false      |\n+--------------------------+-----------------+------------+\n~> octosql \"SELECT COUNT(*) FROM mydb.customers\"\n+-------+\n| count |\n+-------+\n|   183 |\n+-------+\n```\n\nIn order to create your own plugins, see examples of existing plugins:\n- [MySQL](https://github.com/cube2222/octosql-plugin-mysql)\n- [PostgreSQL](https://github.com/cube2222/octosql-plugin-postgres)\n- [Random Data](https://github.com/cube2222/octosql-plugin-random_data)\n\nTo test plugins while developing locally, put the plugin binary into `~/.octosql/plugins/core/octosql-plugin-<plugin name>/0.1.0/octosql-plugin-<plugin name>`. That's the location where OctoSQL will be looking for it.\n\n## Troubleshooting\nOctoSQL writes logs to `~/.octosql/logs.txt`, which is the place to look for any errors or issues during execution. Only logs of the most recent execution are kept.\n\n## Advanced Features\n\n### The Type System\n\nOctoSQL is statically typed. That means that queries are verified, typechecked, and optimized based on the schemas of the tables and types of any values used in the query.\n\nMost of the type system is straight-forward and intuitive, similar to what you'd find in other SQL dialects, even though the types have names which are closer to common programming languages, not SQL databases - in OctoSQL you'll find `String`'s, not `varchar`'s.\n\nHowever, OctoSQL also supports **union types**, which means that a value might be one of multiple types. For example, you might have a dataset where a column is usually a Float, but occasionally also a String with the Float inside. Thus, the type of the column would be `Float | String`.\n\nMoreover, `NULL` is its own type, which means that a nullable `Int` column would be represented as `Int | NULL` in OctoSQL.\n\nThere's a few helper features to handle this union types in OctoSQL.\n\nFirst, whenever a type, i.e. `String | Int`, is used in a place where a subtype, i.e. `Int`, is expected, OctoSQL will add a dynamic runtime check which will fail execution only if a `String` value actually ever reaches that place.\n\nSecond, you can use type assertions to get a value only if it's of a certain type and otherwise evaluate to `NULL`. The syntax for that is `value::type`. So for example we might have a column `age` of type `String | Int` and would like to get its value only if it's an Int. We can write `age::Int` to express that.\n\nThird, there's a bunch of conversion functions which can help you turn types into other types. For example, the `int` function is able to turn values of many types, including strings, to integers. You could use it like this: `int(age_string)`.\n\nFourth, and final, there's the `COALESCE` operator which accepts an arbitrary number of arguments and returns the first non-null one. It works very well with what's described in the previous two paragraphs. This way, if you have an `age` column of type `String | Int` and would like to clean it up, you can write `COALESCE(age::int, int(age::string), 0)`. This would return the value of `age` as-is if it's an `Int`, try to parse it if it's a `String`, and just evaluate to `0` if that fails.\n\nAdditionally, you can work with objects and lists using the following syntax:\n- List access: `list[index]`\n- Object field access: `object->field`\n\n### Explaining Query Plans\n\nYou can use the `--explain` flag to get a visual explanation of the query plan. Setting it to 1 gives you a query plan but without type and schema information, setting it to 2 includes those too. For the visualization to work you need to have the graphviz dot command installed.\n\nFor example, running:\n```bash\noctosql \"SELECT email, COUNT(*) as invoice_count\n         FROM invoices.csv JOIN mydb.customers ON invoices.customer_id = customers.id\n         WHERE first_name <= 'D'\n         GROUP BY email\n         ORDER BY invoice_count DESC\" --explain 1\n```\nwill produce the following output:\n![Explain](images/octosql-explain.png)\n\nHere we can see that the `first_name <= 'D'` predicate has been pushed down to the `mydb.customers` table query.\n\n### Dataflow\n\nOctoSQL is a dataflow engine. In practice that means it can execute a query and then update it based on changes in the inputs. The way this works in practice is by using retractions, each record sent internally has a `retraction` flag dictating whether it's an `undo` or not.\n\nThis also means that OctoSQL can work very well with endless streams of data, or display partial results before calculating the full query.\n\nIn order to handle that well, OctoSQL contains the concept of record event times and watermarks. Each Record can have an Event Time (the time when it originally happened). Watermarks (special metadata records) are used to signal the timestamp that will be the lower bound for all future records. I.e. if you have a watermark of `2021-12-13T00:11:03Z` then all future records will have an event time that is past that timestamp. This let's us understand which Records cannot be retracted anymore, and is very useful when grouping by time windows.\n\nOctoSQL is also internally consistent as defined by [this article](https://www.scattered-thoughts.net/writing/internal-consistency-in-streaming-systems/). This means that the live output at any given time will be a correct output for a common time-prefix of all the inputs. If you're using the `stream-native` output, this guarantee is satisfied whenever a watermark is emitted. (you can treat watermarks as atomic transactions as far as the output is concerned)\n\nThat means, that if you have two input streams, and one input stream is a few minutes behind the other, so for example its watermark value is `2021-12-13T00:11:03Z` and the watermark of the other one is `2021-12-13T00:11:07Z`, then the output of OctoSQL at that time will be a correct output based on all events up to `2021-12-13T00:11:03Z` from both streams. The records in the second stream between `2021-12-13T00:11:03Z` and `2021-12-13T00:11:07Z` will be buffered until the first stream catches up.\n\nFor `GROUP BY` queries you can specify when you want to udpate the output using the `TRIGGER` clause: `SELECT ... FROM ... GROUP BY ... TRIGGER COUNTING 300, ON WATERMARK, ON END OF STREAM`. You can use the Counting Trigger and/or the Watermark Trigger and/or the End Of Stream Trigger; it defaults to the End Of Stream trigger.\n\nThe Watermark Trigger sends values for keys whenever the Watermark rises above the Event Time of the key. The Counting Trigger sends values every time a given number of records arrive for a key. The End Of Stream Trigger sends values for all keys when the stream is over.\n\nWe can take a look at an example query which simulates a stream using a JSON file:\n```sql\nWITH\n  with_watermark AS (SELECT *\n                     FROM max_diff_watermark(source=>TABLE(clicks.json),\n                                              max_diff=>INTERVAL 5 SECONDS,\n                                              time_field=>DESCRIPTOR(time), resolution=>INTERVAL 10 SECONDS) c),\n  with_tumble AS (SELECT *\n                  FROM tumble(source=>TABLE(with_watermark),\n                              window_length=>INTERVAL 1 MINUTE,\n                              offset=>INTERVAL 0 SECONDS) c),\n  counts_per_user AS (SELECT window_end, user_id, COUNT(*) as clicks\n                      FROM with_tumble\n                      GROUP BY window_end, user_id, TRIGGER ON WATERMARK, COUNTING 500)\nSELECT window_end, user_id, clicks\nFROM counts_per_user\n```\nIt uses [Table Valued Functions](#table-valued-functions) extensively.\n\nFirst we create a stream of clicks with Watermarks that lag the latest Event Time seen so far in a Record by 5 seconds. Then organize records into tumbling one-minute windows - each Record gets a new `window_end` field that indicates the end of the window the Record belongs to and becomes its new Event Time. Finally, we group the clicks by user and time window, emitting the count every 500 Records per key, and after we get the Watermark for the window. As you can see on the demo below, for each window we'll get intermediate results and the full result when the Watermark arrives.\n\n![Demo](images/octosql-demo-dataflow.gif)\n\n### Table Valued Functions\n\nOctoSQL supports Table Valued Functions, which are functions that return a stream of Records as their output.\nThe following functions are available:\n- range: constructs a sequence of integers\n  - arguments\n    - start: expression - required - inclusive start of range\n    - end: expression - required - exclusive end of range\n- poll: polls a finite subquery periodically, emitting the current contents of the table\n  - arguments\n    - source: table - required - finite table to poll\n    - poll_interval: expression - optional - interval between polls\n- tumble: assigns records to tumbling windows\n  - arguments\n    - source: table - required - source table\n    - window_length: expression - required - length of the window as an interval\n    - time_field: descriptor - optional - field to use as the Event Time for the windows\n    - offset: expression - optional - offset of the window relative to the beginning of the epoch\n- max_diff_watermark: passes the Records forward as-is, while updating their Event Time field to be the field referenced by the `time_field` argument, and sending Watermarks such that the Watermarks are `max_diff` interval before the latest seen Record Event Time\n  - arguments\n    - source: table - required - source table\n    - max_diff: expression - required - difference between the latest Event Time and the Watermark\n    - time_field: descriptor - required - field to use as the Event Time\n    - resolution: expression - optional - resolution of the Watermarks\n\nTable valued functions must be aliased when used:\n```sql\nSELECT * FROM range(start=>1, end=>10) r\n```\n\nYou can specify table arguments using the TABLE(...) operator and field descriptors using the DESCRIPTOR(...) operator. An example query using both of these types of arguments is shown in the [Dataflow section](#dataflow).\n\nThe TABLE operator can be used to specify both a simple table name or another table valued function:\n```sql\nSELECT * FROM poll(source=>TABLE(range(start=>1,end=>10) r)) r\n```\nor even a whole subquery, but then you have to use another set of parentheses:\n```sql\nSELECT * FROM poll(source=>TABLE((SELECT * FROM range(start=>1,end=>10) r) r)) r\n```\n\n### Join Types\n\nOctoSQL supports two Join strategies: Stream Join and Lookup Join.\n\nOne bit of nomenclature before moving forward: watermarked streams are streams that have an Event Time field, emit Watermarks, and are possibly infinite.\n\n#### Stream Join\nA Stream Join reads both input streams while storing all Records in memory, matching them by the key, and emitting them as they are processed.\n\nIt supports watermarked streams on both sides and the output Watermark will be set to the minimum of both input stream Watermarks in that case. Records newer than the minimum of the input Watermarks will be buffered, not processed, thus guaranteeing [internal consistency](https://www.scattered-thoughts.net/writing/internal-consistency-in-streaming-systems/).\n\nRecords with an event time of zero are never buffered.\n\nIf you only have one watermarked input stream, then its watermarks will be used, and the other stream will be read fully before emitting any output Records.\n\nIf none of the input streams is watermarked, then the Records will be processed without buffering. \n\nThe Stream Join is the default join type, but can also be used by explicitly specifying the `STREAM JOIN` operator.\n\n#### Lookup Join\nA Lookup Joins reads Records from the left input (which can be watermarked) and for each Record gets the relevant Records from the right side (which can't be watermarked). Thus, the right side will be evaluated once per left-side Record. \n\nThis also gives OctoSQL more room for optimization, as it can push the Join predicate down to the right-side input, possibly reading only a small subset of the whole right-side input. This is very useful when the left-side input is very small, i.e., a CSV file with a few rows, the right-side input is huge, i.e., a PostgreSQL table with millions of rows, and you expect each left-side Record to be matched with just a few right-side Records. You can make sure this optimization succeeded by using the `--explain` flag and checking whether the predicates are pushed under the right-side input datasource.\n\nThe Lookup Join can be used by explicitly specifying the `LOOKUP JOIN` operator.\n\n## Benchmarks\n\nThe benchmarks were run on a 2021 MacBook Pro 16 / M1 Max / 32 GB / 1 TB. All binaries are native ARM binaries compiled for Apple Silicon.\n\nThe benchmark script can be found [here](benchmarks/benchmarks.sh).\n\nIt runs the `SELECT passenger_count, COUNT(*), AVG(total_amount) FROM taxi.csv GROUP BY passenger_count` query against the well-known NYC Yellow Taxi Trip Dataset. Specifically, the CSV file from April 2021 is used. It's a 200MB CSV file with ~2 million rows, 18 columns, and mostly numerical values.\n\n| Command                                                                                                                 | Version |        Mean [s] |                  Relative |\n|:------------------------------------------------------------------------------------------------------------------------|--------:|----------------:|--------------------------:|\n| `octosql \"SELECT passenger_count, COUNT(*), AVG(total_amount) FROM taxi.csv GROUP BY passenger_count\"`                  |   0.8.0 |   1.980 ± 0.004 |                      1.00 |\n| `q -d ',' -H \"SELECT passenger_count, COUNT(*), AVG(total_amount) FROM taxi.csv GROUP BY passenger_count\"`              |   3.1.6 |  16.042 ± 0.058 |                      8.10 |\n| `q -d ',' -H -C readwrite \"SELECT passenger_count, COUNT(*), AVG(total_amount) FROM taxi.csv GROUP BY passenger_count\"` |   3.1.6 |   1.691 ± 0.129 |                      0.85 |\n| `textql -header -sql \"SELECT passenger_count, COUNT(*), AVG(total_amount) FROM taxi GROUP BY passenger_count\" taxi.csv` |   2.0.3 |  15.513 ± 0.047 |                      7.83 |\n| `datafusion-cli -f datafusion_commands.txt`                                                                             |   0.9.0 |   0.432 ± 0.002 |                      0.22 |\n| `dsq taxi.csv \"SELECT passenger_count, COUNT(*), AVG(total_amount) FROM {} GROUP BY passenger_count\"`                   |  0.21.0 |  20.756 ± 0.272 |                      10.48 |\n| `dsq --cache taxi.csv \"SELECT passenger_count, COUNT(*), AVG(total_amount) FROM {} GROUP BY passenger_count\"`           |  0.21.0 |  0.879 ± 0.022 |                      0.44 |\n| `spyql \"SELECT passenger_count, count_agg(*), avg_agg(total_amount) FROM csv GROUP BY passenger_count\" < taxi.csv`      |   0.6.0 |  11.430 ± 0.099 |                      5.77 |\n\nHere we can see that OctoSQL is fairly good performance wise.\n\nq and dsq with caching beat OctoSQL, but that's because caching means data loading from CSV is omitted, and the optimized SQLite format is used directly, so the CSV parsing bit is not really benchmarked for them.\n\nNon-cached q and textql, dsq are considerably slower, most probably because they have to parse the whole CSV file to put it into SQLite and only then query it. OctoSQL runs queries directly on the CSV file, so it's able to use its optimizer to avoid loading columns which aren't used in the query.\n\nDataFusion is faster than OctoSQL for CSV queries like this one.\n\n## Contributing\n\nOctoSQL doesn't accept external contributions to its source code right now, but you can raise issues or develop external plugins for database types you'd like OctoSQL to support. Create a Pull Request to add a plugin to the core plugins repository (which is contained in the plugin_repository.json file). You can find more details in the [Plugins section](#plugins)\n\n## Building From Source\n\nOctoSQL can be built from source by running `go install` inside of the cloned repository. Go 1.18+ is required."
}
