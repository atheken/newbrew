{
  "name": "qsv",
  "full_name": "qsv",
  "tap": "homebrew/core",
  "oldname": null,
  "oldnames": [],
  "aliases": [],
  "versioned_formulae": [],
  "desc": "Ultra-fast CSV data-wrangling toolkit",
  "license": "MIT or Unlicense",
  "homepage": "https://github.com/jqnatividad/qsv",
  "versions": {
    "stable": "0.109.0",
    "head": "HEAD",
    "bottle": true
  },
  "urls": {
    "stable": {
      "url": "https://github.com/jqnatividad/qsv/archive/refs/tags/0.109.0.tar.gz",
      "tag": null,
      "revision": null,
      "checksum": "c48d7f5a174d3f80781ae9feb16173d6c5058e4f50916ff2dd77e1ade84a4dbc"
    },
    "head": {
      "url": "https://github.com/jqnatividad/qsv.git",
      "branch": "master"
    }
  },
  "revision": 0,
  "version_scheme": 0,
  "bottle": {
    "stable": {
      "rebuild": 0,
      "root_url": "https://ghcr.io/v2/homebrew/core",
      "files": {
        "arm64_ventura": {
          "cellar": ":any_skip_relocation",
          "url": "https://ghcr.io/v2/homebrew/core/qsv/blobs/sha256:9d06648b003d2960121eef5846d76635410851cac6260747b906e241ee422805",
          "sha256": "9d06648b003d2960121eef5846d76635410851cac6260747b906e241ee422805"
        },
        "arm64_monterey": {
          "cellar": ":any_skip_relocation",
          "url": "https://ghcr.io/v2/homebrew/core/qsv/blobs/sha256:06ff3a693a60226bef712bb87bac954ae1fdc764e777dfbe2dbbff2c27c36d03",
          "sha256": "06ff3a693a60226bef712bb87bac954ae1fdc764e777dfbe2dbbff2c27c36d03"
        },
        "arm64_big_sur": {
          "cellar": ":any_skip_relocation",
          "url": "https://ghcr.io/v2/homebrew/core/qsv/blobs/sha256:93bdbd6bbdb9ea00e40fa5173a1bfc20019b48c53fd968ff7f5ca8a591b0134b",
          "sha256": "93bdbd6bbdb9ea00e40fa5173a1bfc20019b48c53fd968ff7f5ca8a591b0134b"
        },
        "ventura": {
          "cellar": ":any_skip_relocation",
          "url": "https://ghcr.io/v2/homebrew/core/qsv/blobs/sha256:5ef919665eecd934091224dbb515a54f6c622ff420c447f4ada39c52de589de1",
          "sha256": "5ef919665eecd934091224dbb515a54f6c622ff420c447f4ada39c52de589de1"
        },
        "monterey": {
          "cellar": ":any_skip_relocation",
          "url": "https://ghcr.io/v2/homebrew/core/qsv/blobs/sha256:127faf41a9985187a77f53094e3cb1abe25504fe9525f60f179aace2b801444c",
          "sha256": "127faf41a9985187a77f53094e3cb1abe25504fe9525f60f179aace2b801444c"
        },
        "big_sur": {
          "cellar": ":any_skip_relocation",
          "url": "https://ghcr.io/v2/homebrew/core/qsv/blobs/sha256:85524fb65341a0e2a09055b8e6bce48ae8c26bd745fe924619aae229d3305935",
          "sha256": "85524fb65341a0e2a09055b8e6bce48ae8c26bd745fe924619aae229d3305935"
        },
        "x86_64_linux": {
          "cellar": ":any_skip_relocation",
          "url": "https://ghcr.io/v2/homebrew/core/qsv/blobs/sha256:460da51a0af8168a6657e467763734497d48f150833c39abbfe5c20dd5a14b92",
          "sha256": "460da51a0af8168a6657e467763734497d48f150833c39abbfe5c20dd5a14b92"
        }
      }
    }
  },
  "keg_only": false,
  "keg_only_reason": null,
  "options": [],
  "build_dependencies": [
    "rust"
  ],
  "dependencies": [
    "libmagic"
  ],
  "test_dependencies": [],
  "recommended_dependencies": [],
  "optional_dependencies": [],
  "uses_from_macos": [],
  "uses_from_macos_bounds": [],
  "requirements": [],
  "conflicts_with": [],
  "conflicts_with_reasons": [],
  "link_overwrite": [],
  "caveats": null,
  "installed": [],
  "linked_keg": null,
  "pinned": false,
  "outdated": false,
  "deprecated": false,
  "deprecation_date": null,
  "deprecation_reason": null,
  "disabled": false,
  "disable_date": null,
  "disable_reason": null,
  "post_install_defined": false,
  "service": null,
  "tap_git_head": "4eeae4ea50839e967536ba646d5e0ed6fbcbad7f",
  "ruby_source_path": "Formula/qsv.rb",
  "ruby_source_checksum": {
    "sha256": "b0ded9b44590b0b090fabfbe3351a4599e7fe269e038417d2c5ac818940dcdbd"
  },
  "date_added": "2022-07-10T17:40:39+00:00",
  "readme": "## qsv: Ultra-fast CSV data-wrangling toolkit\n\n[![Linux build status](https://github.com/jqnatividad/qsv/actions/workflows/rust.yml/badge.svg)](https://github.com/jqnatividad/qsv/actions/workflows/rust.yml)\n[![Windows build status](https://github.com/jqnatividad/qsv/actions/workflows/rust-windows.yml/badge.svg)](https://github.com/jqnatividad/qsv/actions/workflows/rust-windows.yml)\n[![macOS build status](https://github.com/jqnatividad/qsv/actions/workflows/rust-macos.yml/badge.svg)](https://github.com/jqnatividad/qsv/actions/workflows/rust-macos.yml)\n[![Security audit](https://github.com/jqnatividad/qsv/actions/workflows/security-audit.yml/badge.svg)](https://github.com/jqnatividad/qsv/actions/workflows/security-audit.yml)\n[![Downloads](https://img.shields.io/github/downloads/jqnatividad/qsv/total?logo=github)](https://github.com/jqnatividad/qsv/releases/latest)\n[![Clones](https://img.shields.io/badge/dynamic/json?color=success&label=clones&query=count&url=https://gist.githubusercontent.com/jqnatividad/13f60ad0b54856a55f60b8e653079349/raw/clone.json&logo=github)](https://github.com/MShawon/github-clone-count-badge)\n[![Discussions](https://img.shields.io/github/discussions/jqnatividad/qsv)](https://github.com/jqnatividad/qsv/discussions)\n[![HomeBrew](https://img.shields.io/homebrew/v/qsv?logo=homebrew)](https://formulae.brew.sh/formula/qsv)\n[![Crates.io](https://img.shields.io/crates/v/qsv.svg?logo=crates.io)](https://crates.io/crates/qsv)\n[![Crates.io downloads](https://img.shields.io/crates/d/qsv?color=orange&label=crates.io%20downloads)](https://crates.io/crates/qsv)\n[![Minimum supported Rust version](https://img.shields.io/badge/Rust-1.71.1-red?logo=rust)](#minimum-supported-rust-version)\n\n<div align=\"center\">\n\n &nbsp;          |  Table of Contents\n:--------------------------|:-------------------------\n![qsv logo](docs/images/qsv-logo.png)<br/>[_Hi-ho \"Quicksilver\" away!_](https://www.youtube.com/watch?v=p9lf76xOA5k)<br/><sub><sup>[logo details](https://github.com/jqnatividad/qsv/discussions/295)</sup></sub><br/>|qsv (pronounced \"Quicksilver\") is a<br>command line program for indexing, slicing,<br>analyzing, filtering, enriching, validating &<br>joining CSV files.<br>Commands are simple, fast & composable.<br><br>* [Available Commands](#available-commands)<br>* [Installation Options](#installation-options)<br> * [Whirlwind Tour](docs/whirlwind_tour.md#a-whirlwind-tour) / [Notebooks](contrib/notebooks/)<br>* [Cookbook](https://github.com/jqnatividad/qsv/wiki/Cookbook#cookbook)<br>* [FAQ](https://github.com/jqnatividad/qsv/discussions/categories/faq)<br>* [Changelog](https://github.com/jqnatividad/qsv/blob/master/CHANGELOG.md#changelog)<br>* [Performance Tuning](docs/PERFORMANCE.md#performance-tuning)<br>* [Benchmarks](docs/BENCHMARKS.md)<br>* [Environment Variables](docs/ENVIRONMENT_VARIABLES.md)<br>* [Feature Flags](#feature-flags)<br>* [Testing](#testing)<br>* [NYC School of Data 2022 slides](https://docs.google.com/presentation/d/e/2PACX-1vQ12ndZL--gkz0HLQRaxqsNOwzddkv1iUKB3sq661yA77OPlAsmHJHpjaqt9s9QEf73VqMfb0cv4jHU/pub?start=false&loop=false&delayms=3000)<br>* [Sponsor](#sponsor)\n\n</div>\n\n> ‚ÑπÔ∏è **NOTE:** Quicksilver (qsv) is a fork of the popular [xsv](https://github.com/BurntSushi/xsv) utility, merging several pending PRs [since xsv 0.13.0's May 2018 release](https://github.com/BurntSushi/xsv/issues/267). On top of xsv's 20 commands, it adds numerous new features; 36 additional commands; 6 `apply` subcommands & 35 operations; 5 `to` subcommands; 3 `cat` subcommands; and 4 `snappy` subcommands.\nSee [FAQ](https://github.com/jqnatividad/qsv/discussions/categories/faq) for more details.\n\n## Available commands\n\n| Command | Description |\n| --- | --- |\n| [apply](/src/cmd/apply.rs#L2)<br>‚ú®üöÄüß†ü§ñ | Apply series of string, date, math, currency & geocoding transformations to a CSV column. It also has some basic [NLP](https://en.wikipedia.org/wiki/Natural_language_processing) functions ([similarity](https://crates.io/crates/strsim), [sentiment analysis](https://crates.io/crates/vader_sentiment), [profanity](https://docs.rs/censor/latest/censor/), [eudex](https://github.com/ticki/eudex#eudex-a-blazingly-fast-phonetic-reductionhashing-algorithm) & [language detection](https://crates.io/crates/whatlang)).  |\n| <a name=\"applydp_deeplink\"></a>[applydp](/src/cmd/applydp.rs#L2)<br>üöÄ ![CKAN](docs/images/ckan.png)| applydp is a slimmed-down version of `apply` with only [Datapusher+](https://github.com/dathere/datapusher-plus) relevant subcommands/operations (`qsvdp` binary variant only). |\n| [behead](/src/cmd/behead.rs#L2) | Drop headers from a CSV.  |\n| [cat](/src/cmd/cat.rs#L2) | Concatenate CSV files by row or by column. |\n| [count](/src/cmd/count.rs#L2)<br>üìáüèéÔ∏è | Count the rows in a CSV file. (15.82 seconds for 15gb, 27m row NYC 311 dataset without an index. Instantaneous with an index.) |\n| [dedup](/src/cmd/dedup.rs#L2)<br>ü§ØüöÄ | Remove duplicate rows (See also `extdedup`, `extsort`, `sort` & `sortcheck` commands). |\n| [describegpt](/src/cmd/describegpt.rs#L2)<br>üåêü§ñ | Infer extended metadata about a CSV using a GPT model from [OpenAI's API](https://platform.openai.com/docs/introduction). |\n| [diff](/src/cmd/diff.rs#L2)<br>üöÄ | Find the difference between two CSVs with ludicrous speed!<br/>e.g. *compare two CSVs with 1M rows x 9 columns in under 600ms!* |\n| [enum](/src/cmd/enumerate.rs#L2) | Add a new column enumerating rows by adding a column of incremental or uuid identifiers. Can also be used to copy a column or fill a new column with a constant value.  |\n| [excel](/src/cmd/excel.rs#L2) | Exports a specified Excel/ODS sheet to a CSV file. |\n| [exclude](/src/cmd/exclude.rs#L2)<br>üìá | Removes a set of CSV data from another set based on the specified columns.  |\n| [explode](/src/cmd/explode.rs#L2) | Explode rows into multiple ones by splitting a column value based on the given separator.  |\n| [extdedup](/src/cmd/extdedup.rs#L2)<br> | Remove duplicate rows from an arbitrarily large CSV/text file using a memory-mapped, [on-disk hash table](https://crates.io/crates/odht). Unlike the `dedup` command, this command does not load the entire file into memory nor does it sort the deduped file. |\n| [extsort](/src/cmd/extsort.rs#L2)<br>üöÄ | Sort an arbitrarily large CSV/text file using a multithreaded [external merge sort](https://en.wikipedia.org/wiki/External_sorting) algorithm. |\n| [fetch](/src/cmd/fetch.rs#L3)<br>‚ú®üß†üåê | Fetches data from web services for every row using **HTTP Get**. Comes with [HTTP/2](https://http2-explained.haxx.se/en/part1) [adaptive flow control](https://medium.com/coderscorner/http-2-flow-control-77e54f7fd518), [jql](https://github.com/yamafaktory/jql#%EF%B8%8F-usage) JSON query language support, dynamic throttling ([RateLimit](https://www.ietf.org/archive/id/draft-ietf-httpapi-ratelimit-headers-06.html)) & caching with optional [Redis](https://redis.io/) support for persistent caching. |\n| [fetchpost](/src/cmd/fetchpost.rs#L3)<br>‚ú®üß†üåê | Similar to `fetch`, but uses **HTTP Post**. ([HTTP GET vs POST methods](https://www.geeksforgeeks.org/difference-between-http-get-and-post-methods/)) |\n| [fill](/src/cmd/fill.rs#L2) | Fill empty values.  |\n| [fixlengths](/src/cmd/fixlengths.rs#L2) | Force a CSV to have same-length records by either padding or truncating them. |\n| [flatten](/src/cmd/flatten.rs#L2) | A flattened view of CSV records. Useful for viewing one record at a time.<br />e.g. `qsv slice -i 5 data.csv \\| qsv flatten`. |\n| [fmt](/src/cmd/fmt.rs#L2) | Reformat a CSV with different delimiters, record terminators or quoting rules. (Supports ASCII delimited data.)  |\n| [foreach](/src/cmd/foreach.rs#L3)<br>‚ú® | Loop over a CSV to execute shell commands. (not available on Windows)  |\n| [frequency](/src/cmd/frequency.rs#L2)<br>üìáüò£üèéÔ∏è | Build [frequency tables](https://statisticsbyjim.com/basics/frequency-table/) of each column. Uses multithreading to go faster if an index is present. |\n| [generate](/src/cmd/generate.rs#L2)<br>‚ú® | Generate test data by profiling a CSV using [Markov decision process](https://crates.io/crates/test-data-generation) machine learning.  |\n| [headers](/src/cmd/headers.rs#L2) | Show the headers of a CSV. Or show the intersection of all headers between many CSV files. |\n| [index](/src/cmd/index.rs#L2) | Create an index (üìá) for a CSV. This is very quick (even the 15gb, 28m row NYC 311 dataset takes all of 15 seconds to index) & provides constant time indexing/random access into the CSV. With an index, `count`, `sample` & `slice` work instantaneously; random access mode is enabled in `luau`; and multithreading (üèéÔ∏è) is enabled for the `frequency`, `split`, `stats`, `schema` & `tojsonl` commands. |\n| [input](/src/cmd/input.rs#L2) | Read CSV data with special quoting, trimming, line-skipping & UTF-8 transcoding rules. Typically used to \"normalize\" a CSV for further processing with other qsv commands. |\n| [join](/src/cmd/join.rs#L2) | Inner, outer, right, cross, anti & semi joins. Automatically creates a simple, in-memory hash index to make it fast.  |\n| [joinp](/src/cmd/joinp.rs#L2)<br>‚ú®üöÄüêª‚Äç‚ùÑÔ∏è | Inner, outer, cross, anti, semi & asof joins using the [Pola.rs](https://www.pola.rs) engine. Unlike the `join` command, `joinp` can process files larger than RAM, is multi-threaded, has join key validation, pre-join filtering, supports [asof joins](https://pola-rs.github.io/polars/py-polars/html/reference/dataframe/api/polars.DataFrame.join_asof.html) & its output doesn't have duplicate columns. However, `joinp` doesn't have an --ignore-case option & it doesn't support right outer joins. |\n| [jsonl](/src/cmd/jsonl.rs#L2) | Convert newline-delimited JSON ([JSONL](https://jsonlines.org/)/[NDJSON](http://ndjson.org/)) to CSV. See `tojsonl` command to convert CSV to JSONL.\n| <a name=\"luau_deeplink\"></a><br>[luau](/src/cmd/luau.rs#L2) üëë<br>‚ú®üìáüåê ![CKAN](docs/images/ckan.png) | Create multiple new computed columns, filter rows, compute aggregations and build complex data pipelines by executing a [Luau](https://luau-lang.org) [0.588](https://github.com/Roblox/luau/releases/tag/0.588) expression/script for every row of a CSV file ([sequential mode](https://github.com/jqnatividad/qsv/blob/bb72c4ef369d192d85d8b7cc6e972c1b7df77635/tests/test_luau.rs#L254-L298)), or using [random access](https://www.webopedia.com/definitions/random-access/) with an index ([random access mode](https://github.com/jqnatividad/qsv/blob/bb72c4ef369d192d85d8b7cc6e972c1b7df77635/tests/test_luau.rs#L367-L415)).<br>Can process a single Luau expression or [full-fledged data-wrangling scripts using lookup tables](https://github.com/dathere/qsv-lookup-tables#example) with discrete BEGIN, MAIN and END sections.<br> It is not just another qsv command, it is qsv's [Domain-specific Language](https://en.wikipedia.org/wiki/Domain-specific_language) (DSL) with [numerous qsv-specific helper functions](https://github.com/jqnatividad/qsv/blob/113eee17b97882dc368b2e65fec52b86df09f78b/src/cmd/luau.rs#L1356-L2290) to build production data pipelines. |\n| [partition](/src/cmd/partition.rs#L2) | Partition a CSV based on a column value. |\n| [pseudo](/src/cmd/pseudo.rs#L2) | [Pseudonymise](https://en.wikipedia.org/wiki/Pseudonymization) the value of the given column by replacing them with an incremental identifier.  |\n| [py](/src/cmd/python.rs#L2)<br>‚ú® | Create a new computed column or filter rows by evaluating a python expression on every row of a CSV file. Python's [f-strings](https://www.freecodecamp.org/news/python-f-strings-tutorial-how-to-use-f-strings-for-string-formatting/) is particularly useful for extended formatting, [with the ability to evaluate Python expressions as well](https://github.com/jqnatividad/qsv/blob/4cd00dca88addf0d287247fa27d40563b6d46985/src/cmd/python.rs#L23-L31). |\n| [rename](/src/cmd/rename.rs#L2) |  Rename the columns of a CSV efficiently. |\n| [replace](/src/cmd/replace.rs#L2) | Replace CSV data using a regex. Applies the regex to each field individually. |\n| [reverse](/src/cmd/reverse.rs#L2)<br>ü§Ø | Reverse order of rows in a CSV. Unlike the `sort --reverse` command, it preserves the order of rows with the same key.  |\n| <a name=\"safenames_deeplink\"></a>[safenames](/src/cmd/safenames.rs#L2)<br>![CKAN](docs/images/ckan.png) | Modify headers of a CSV to only have [\"safe\" names](/src/cmd/safenames.rs#L5-L14) - guaranteed \"database-ready\"/\"CKAN-ready\" names.  |\n| [sample](/src/cmd/sample.rs#L2)<br>üìáüåêüèéÔ∏è | Randomly draw rows (with optional seed) from a CSV using [reservoir sampling](https://en.wikipedia.org/wiki/Reservoir_sampling), using memory proportional to the sample size. If an index is present, using random indexing with constant memory. |\n| [schema](/src/cmd/schema.rs#L2)<br>üìáüò£üèéÔ∏è | Infer schema from CSV data, replete with data type & domain/range validation & output in [JSON Schema](https://json-schema.org/) format. Uses multithreading to go faster if an index is present. See `validate` command to use the generated JSON Schema to validate if similar CSVs comply with the schema. |\n| [search](/src/cmd/search.rs#L2) | Run a regex over a CSV. Applies the regex to each field individually & shows only matching rows.  |\n| [searchset](/src/cmd/searchset.rs#L2) | *Run multiple regexes over a CSV in a single pass.* Applies the regexes to each field individually & shows only matching rows.  |\n| [select](/src/cmd/select.rs#L2) | Select, re-order, duplicate or drop columns.  |\n| [slice](/src/cmd/slice.rs#L2)<br>üìáüèéÔ∏è | Slice rows from any part of a CSV. When an index is present, this only has to parse the rows in the slice (instead of all rows leading up to the start of the slice).  |\n| <a name=\"snappy_deeplink\"></a>[snappy](/src/cmd/snappy.rs#L2)<br>üöÄüåê | Does streaming compression/decompression of the input using Google's [Snappy](https://github.com/google/snappy/blob/main/docs/README.md) framing format ([more info](#snappy-compressiondecompression)). |\n| [sniff](/src/cmd/sniff.rs#L2)<br>üåê ![CKAN](docs/images/ckan.png) | Quickly sniff & infer CSV metadata (delimiter, header row, preamble rows, quote character, flexible, is_utf8, average record length, number of records, content length & estimated number of records if sniffing a CSV on a URL, number of fields, field names & data types). It is also a general mime type detector. |\n| [sort](/src/cmd/sort.rs#L2)<br>üöÄü§Ø | Sorts CSV data in alphabetical (with case-insensitive option), numerical, reverse, unique or random (with optional seed) order (See also `extsort` & `sortcheck` commands).  |\n| [sortcheck](/src/cmd/sortcheck.rs#L2)<br>üìá | Check if a CSV is sorted. With the --json options, also retrieve record count, sort breaks & duplicate count. |\n| [split](/src/cmd/split.rs#L2)<br>üìáüèéÔ∏è | Split one CSV file into many CSV files of N chunks. Uses multithreading to go faster if an index is present. |\n| [sqlp](/src/cmd/sqlp.rs#L2)<br>‚ú®üöÄüêª‚Äç‚ùÑÔ∏è | Run blazing-fast Polars SQL queries against several CSVs - converting queries to [fast LazyFrame expressions](https://pola-rs.github.io/polars-book/user-guide/sql/intro/), processing larger than memory CSV files. |\n| [stats](/src/cmd/stats.rs#L2)<br>üìáü§ØüèéÔ∏è | Compute [summary statistics](https://en.wikipedia.org/wiki/Summary_statistics) (sum, min/max/range, min/max length, mean, stddev, variance, nullcount, sparsity, quartiles, IQR, lower/upper fences, skewness, median, mode/s, antimode/s & cardinality) & make GUARANTEED data type inferences (Null, String, Float, Integer, Date, DateTime, Boolean) for each column in a CSV.<br>Uses multithreading to go faster if an index is present (with an index, can compile \"streaming\" stats on NYC's 311 data (15gb, 28m rows) in less than 20 seconds). |\n| [table](/src/cmd/table.rs#L2)<br>ü§Ø | Show aligned output of a CSV using [elastic tabstops](https://github.com/BurntSushi/tabwriter).  To interactively view CSV files, qsv pairs well with [csvlens](https://github.com/YS-L/csvlens#csvlens). |\n| [to](/src/cmd/to.rs#L2)<br>‚ú®üöÄ | Convert CSV files to [PostgreSQL](https://www.postgresql.org), [SQLite](https://www.sqlite.org/index.html), XLSX, [Parquet](https://parquet.apache.org) and [Data Package](https://datahub.io/docs/data-packages/tabular). |\n| [tojsonl](/src/cmd/tojsonl.rs#L3)<br>üìáüò£üèéÔ∏è | Smartly converts CSV to a newline-delimited JSON ([JSONL](https://jsonlines.org/)/[NDJSON](http://ndjson.org/)). By scanning the CSV first, it \"smartly\" infers the appropriate JSON data type for each column. See `jsonl` command to convert JSONL to CSV. Uses multithreading to go faster if an index is present. |\n| [transpose](/src/cmd/transpose.rs#L2)<br>ü§Ø | Transpose rows/columns of a CSV.  |\n| [validate](/src/cmd/validate.rs#L2)<br>üìáüöÄüåê | Validate CSV data blazingly-fast using [JSON Schema Validation](https://json-schema.org/draft/2020-12/json-schema-validation.html) & put invalid records into a separate file with an accompanying detailed validation error report file (e.g. *up to 350,000 rows/second* using [NYC's 311 schema](https://github.com/jqnatividad/qsv/blob/master/resources/test/311_Service_Requests_from_2010_to_Present-2022-03-04.csv.schema.json) generated by the `schema` command).<br>If no JSON schema file is provided, validates if a CSV conforms to the [RFC 4180 standard](#rfc-4180-csv-standard). |\n\n<div style=\"text-align: right\"><sub><sup>Performance metrics compiled on an M2 Pro 12-core Mac Mini with 32gb RAM</sup></sub></div>\n\n‚ú®: enabled by a [feature flag](#feature-flags).   \nüìá: uses an index when available.   \nü§Ø: loads entire CSV into memory, though `dedup`, `stats` & `transpose` have \"streaming\" modes as well.   \nüò£: uses additional memory proportional to the cardinality of the columns in the CSV.   \nüß†: expensive operations are memoized (cached) with available inter-session Redis caching for fetch commands.    \nüêª‚Äç‚ùÑÔ∏è: command powered by [Pola.rs](https://pola.rs) engine.   \nü§ñ: command uses Natural Language Processing & General AI techniques.  \nüèéÔ∏è: multithreaded and/or faster when an index (üìá) is available.   \nüöÄ: multithreaded even without an index.   \n![CKAN](docs/images/ckan.png) : has [CKAN](https://ckan.org)-aware integration options.    \nüåê: has web-aware options.\n\n## Installation Options\n\n### Option 1: Download Prebuilt Binaries\n\nFull-featured prebuilt [binary variants](#variants) of the latest qsv version for Linux, macOS & Windows are available [for download](https://github.com/jqnatividad/qsv/releases/latest), including binaries compiled with [Rust Nightly](https://stackoverflow.com/questions/70745970/rust-nightly-vs-beta-version) ([more info](https://github.com/jqnatividad/qsv/blob/master/docs/PERFORMANCE.md#nightly-release-builds)).\n\nThese prebuilt binaries are also built with CPU optimizations enabled for x86_64 (e.g. [SSE4.2](https://en.wikipedia.org/wiki/SSE4#SSE4.2), [AVX2](https://en.wikipedia.org/wiki/Advanced_Vector_Extensions#Advanced_Vector_Extensions_2), [AVX512](https://en.wikipedia.org/wiki/Advanced_Vector_Extensions#Advanced_Vector_Extensions_512), etc. on Intel and AMD processors) and Apple Silicon processors ([ARM64 SIMD NEON](https://eclecticlight.co/2021/08/06/accelerating-the-m1-mac-an-introduction-to-simd/)) for even more performance gains.\n\nFor Windows, an MSI Installer wrapping the x86_64-pc-windows-msvc build is also available for download.\n\n### Option 2: Homebrew\n\nFor [macOS and Linux (64-bit)](https://formulae.brew.sh/formula/qsv), you can quickly install qsv with [Homebrew](https://brew.sh). However, only the `apply` and `luau` [features](#feature-flags) are enabled.\n\n```\nbrew install qsv\n```\n\n### Option 3: Install with Rust\n\nIf you have [Rust installed](https://www.rust-lang.org/tools/install), you can also install from source using Rust's cargo command[^1]:\n\n[^1]: Of course, you'll also need a linker & a C compiler. Linux users should generally install GCC or Clang, according to their distribution‚Äôs documentation.\nFor example, if you use Ubuntu, you can install the `build-essential` package. On macOS, you can get a C compiler by running `$ xcode-select --install`.\nFor Windows, this means installing [Visual Studio 2022](https://visualstudio.microsoft.com/downloads/). When prompted for workloads, include \"Desktop Development with C++\",\nthe Windows 10 or 11 SDK & the English language pack, along with any other language packs your require.\n\n```bash\ncargo install qsv --locked --features all_features\n```\n\nThe binary will be installed in `~/.cargo/bin`.\n\nTo install different [variants](#variants) and enable optional features, use cargo `--features` (see [Feature Flags](#feature-flags) for more info):\n\n```bash\n# to install qsv with all features enabled\ncargo install qsv --locked --bin qsv --features feature_capable,apply,generate,luau,fetch,foreach,python,to,self_update,polars\n# or shorthand\ncargo install qsv --locked --bin qsv -F all_features\n\n# or enable only the apply and polars features\ncargo install qsv --locked --bin qsv -F feature_capable,apply,polars\n\n# or to install qsvlite\ncargo install qsv --locked --bin qsvlite -F lite\n\n# or to install qsvdp\ncargo install qsv --locked --bin qsvdp -F datapusher_plus,luau\n```\n\n### Option 4: Compile from Source\n\nCompiling from source also works similarly[^1]:\n\n```bash\ngit clone https://github.com/jqnatividad/qsv.git\ncd qsv\ncargo build --release --locked --bin qsv --features all_features\n```\n\nThe compiled binary will end up in `./target/release/`.\n\nTo compile different [variants](#variants) and enable optional [features](#feature-flags):\n\n```bash\n# to compile qsv with all features enabled\ncargo build --release --locked --bin qsv --features feature_capable,apply,generate,luau,fetch,foreach,python,to,self_update,polars\n# shorthand\ncargo build --release --locked --bin qsv -F all_features\n\n# or build qsv with only the fetch and foreach features enabled\ncargo build --release --locked --bin qsv -F feature_capable,fetch,foreach\n\n# for qsvlite\ncargo build --release --locked --bin qsvlite -F lite\n\n# for qsvdp\ncargo build --release --locked --bin qsvdp -F datapusher_plus,luau\n```\n\nNOTE: To build with Rust nightly, see [Nightly Release Builds](docs/PERFORMANCE.md#nightly-release-builds).\n\n### Variants\n\nThere are three binary variants of qsv:\n* `qsv` - [feature](#feature-flags)-capable(‚ú®), with the [prebuilt binaries](https://github.com/jqnatividad/qsv/releases/latest) enabling all applicable features except Python [^2]\n* `qsvlite` - all features disabled (~13% of the size of `qsv`)\n* `qsvdp` - optimized for use with [DataPusher+](https://github.com/dathere/datapusher-plus) with only DataPusher+ relevant commands; an embedded [`luau`](#luau_deeplink) interpreter; [`applydp`](#applydp_deeplink), a slimmed-down version of the `apply` feature; the `--progressbar` option disabled; and the self-update only checking for new releases, requiring an explicit `--update` (~12% of the the size of `qsv`).\n\n[^2]: The `foreach` feature is not available on Windows. The `python` feature is not enabled on the prebuilt binaries. Compile qsv with Python development environment installed if you want to enable the `python` feature (Python 3.7 & above supported). The `luau` feature is enabled by default on the prebuilt binaries if the platform supports it.  \n\n## Regular Expression Syntax\n\nThe `--select` option and several commands (`apply`, `applydp`, `replace`, `schema`, `search`, `searchset`, `select` & `sqlp`) allow the user to specify regular expressions. We use the [`regex`](https://docs.rs/regex) crate to parse, compile and execute these expressions. [^3]\n\n[^3]: This is the same regex engine used by [`ripgrep`](https://github.com/BurntSushi/ripgrep#ripgrep-rg) - the [blazingly fast grep replacement](https://blog.burntsushi.net/ripgrep/) that powers Visual Studio's [magical](https://lab.cccb.org/en/arthur-c-clarke-any-sufficiently-advanced-technology-is-indistinguishable-from-magic/) [\"Find in Files\"](https://github.com/microsoft/vscode-ripgrep) feature.\n\nIts syntax can be found [here](https://docs.rs/regex/latest/regex/#syntax) and *\"is similar to other regex engines, but it lacks several features that are not known how to implement efficiently. This includes, but is not limited to, look-around and backreferences. In exchange, all regex searches in this crate have worst case O(m * n) time complexity, where m is proportional to the size of the regex and n is proportional to the size of the string being searched.\"*\n\nIf you want to test your regular expressions, [regex101](https://regex101.com) supports the syntax used by the `regex` crate. Just select the \"Rust\" flavor.\n\n## File formats\n\nqsv recognizes UTF-8/ASCII encoded, CSV (`.csv`) & TSV files (`.tsv` & `.tab`). CSV files are assumed to have \",\" (comma) as a delimiter,\nand TSV files, \"\\t\" (tab) as a delimiter. The delimiter is a single ascii character that can be set either by the `--delimiter` command-line option or\nwith the `QSV_DEFAULT_DELIMITER` environment variable or automatically detected when `QSV_SNIFF_DELIMITER` is set.\n\nWhen using the `--output` option, qsv will UTF-8 encode the file & automatically change the delimiter used in the generated file based on the file extension - i.e. comma for `.csv`, tab for `.tsv` & `.tab` files.\n\n[JSONL](https://jsonlines.org/)/[NDJSON](http://ndjson.org/) files are also recognized & converted to/from CSV with the [`jsonl`](/src/cmd/jsonl.rs#L11) and [`tojsonl`](/src/cmd/tojsonl.rs#L12) commands respectively.\n\nThe `fetch` & `fetchpost` commands also produces JSONL files when its invoked without the `--new-column` option & TSV files with the `--report` option.\n\nThe `excel`, `safenames`, `sniff`, `sortcheck` & `validate` commands produce JSON files with their JSON options following the [JSON API 1.1 specification](https://jsonapi.org/format/).\n\nThe `schema` command produces a [JSON Schema Validation (Draft 7)](https://json-schema.org/draft/2020-12/json-schema-validation.html) file with the \".schema.json\" file extension, which can be used with the `validate` command to validate other CSV files with a similar schema.\n\nThe `excel` command recognizes Excel & Open Document Spreadsheet(ODS) files (`.xls`, `.xlsx`, `.xlsm`, `.xlsb` & `.ods` files).\n\nThe `to` command converts CSVs to `.xlsx`, [Parquet](https://parquet.apache.org) & [Data Package](https://datahub.io/docs/data-packages/tabular) files, and populates [PostgreSQL](https://www.postgresql.org) and [SQLite](https://www.sqlite.org/index.html) databases.\n\nThe `sqlp` command produces query results in CSV, JSON, Parquet & [Arrow IPC](https://arrow.apache.org/docs/format/Columnar.html#ipc-file-format) formats. Polars SQL also supports reading external files directly with its `read_ndjson`, `read_csv`, `read_parquet` & `read_ipc` [table functions](https://github.com/pola-rs/polars/blob/c7fa66a1340418789ec66bdedad6654281afa0ab/polars/polars-sql/src/table_functions.rs#L9-L36).\n\n### Snappy Compression/Decompression\n\nqsv supports *automatic compression/decompression* using the [Snappy frame format](https://github.com/google/snappy/blob/main/framing_format.txt). Snappy was chosen instead of more popular compression formats like gzip because it was designed for [high-performance streaming compression & decompression](https://github.com/google/snappy/tree/main/docs#readme) (up to 2.58 gb/sec compression, 0.89 gb/sec decompression).\n\nFor all commands except the `index`, `extdedup` & `extsort` commands, if the input file has an \".sz\" extension, qsv will *automatically* do streaming decompression as it reads it. Further, if the input file has an extended CSV/TSV \".sz\" extension (e.g nyc311.csv.sz/nyc311.tsv.sz/nyc311.tab.sz), qsv will also use the file extension to determine the delimiter to use.   \n\nSimilarly, if the `--output` file has an \".sz\" extension, qsv will *automatically* do streaming compression as it writes it.\nIf the output file has an extended CSV/TSV \".sz\" extension, qsv will also use the file extension to determine the delimiter to use.  \n\nNote however that compressed files cannot be indexed, so index-accelerated commands (`frequency`, `schema`, `split`, `stats`, `tojsonl`) will not be multi-threaded. Random access is also disabled without an index, so `slice` will not be instantaneous and `luau`'s random-access mode will not be available.\n\nThere is also a dedicated [`snappy`](/src/cmd/snappy.rs#L2) command with four subcommands for direct snappy file operations ‚Äî a multithreaded `compress` subcommand (4-5x faster than the built-in, single-threaded auto-compression); a `decompress` subcommand with detailed compression metadata; a `check` subcommand to quickly inspect if a file has a Snappy header; and a `validate` subcommand to confirm if a Snappy file is valid.\n\nThe `snappy` command can be used to compress/decompress ANY file, not just CSV/TSV files.\n\nUsing the `snappy` command, we can compress NYC's 311 data (15gb, 28m rows) to 4.95 gb in *5.77 seconds* with the multithreaded `compress` subcommand - *2.58 gb/sec* with a 0.33 (3.01:1) compression ratio.  With `snappy decompress`, we can roundtrip decompress the same file in *16.71 seconds* - *0.89 gb/sec*.\n\nCompare that to [zip 3.0](https://infozip.sourceforge.net/Zip.html), which compressed the same file to 2.9 gb in *248.3 seconds on the same machine - 43x slower at 0.06 gb/sec* with a 0.19 (5.17:1) compression ratio - for just an additional 14% (2.45 gb) of saved space. zip also took 4.3x longer to roundtrip decompress the same file in *72 seconds* - *0.20 gb/sec*.\n\n## RFC 4180 CSV Standard\n\nqsv follows the [RFC 4180](https://datatracker.ietf.org/doc/html/rfc4180) CSV standard. However, in real life, CSV formats vary significantly & qsv is actually not strictly compliant with the specification so it can process \"real-world\" CSV files.\nqsv leverages the awesome [Rust CSV](https://docs.rs/csv/latest/csv/) crate to read/write CSV files.\n\nClick [here](https://docs.rs/csv-core/latest/csv_core/struct.Reader.html#rfc-4180) to find out more about how qsv conforms to the standard using this crate.\n\nWhen dealing with \"atypical\" CSV files, you can use the `input` command to normalize them to be RFC 4180-compliant.\n\n## UTF-8 Encoding\n\nqsv requires UTF-8 encoded input (of which ASCII is a subset).\n\nShould you need to re-encode CSV/TSV files, you can use the `input` command to transcode to UTF-8. It will replace all invalid UTF-8 sequences with `ÔøΩ` ([U+FFFD REPLACEMENT CHARACTER](https://doc.rust-lang.org/std/char/constant.REPLACEMENT_CHARACTER.html)). Alternatively, there are several utilities you can use to do so on [Linux/macOS](https://stackoverflow.com/questions/805418/how-can-i-find-encoding-of-a-file-via-a-script-on-linux) & [Windows](https://superuser.com/questions/1163753/converting-text-file-to-utf-8-on-windows-command-prompt).\n\n### Windows Usage Note\n\nUnlike other modern operating systems, Microsoft Windows' [default encoding is UTF16-LE](https://stackoverflow.com/questions/66072117/why-does-windows-use-utf-16le). This will cause problems when redirecting qsv's output to a CSV file & trying to open it with Excel (which ignores the comma delimiter, with everything in the first column):\n\n```\n# the following command will produce a UTF16-LE encoded CSV file on Windows\nqsv stats wcp.csv > wcpstats.csv\n```\n\nWhich is weird, since you would think [Microsoft's own Excel would properly recognize UTF16-LE encoded CSV files](https://answers.microsoft.com/en-us/msoffice/forum/all/opening-csv-file-with-utf16-encoding-in-excel-2010/ed522cb9-e88d-4b82-b88e-a2d4bd99f874?auth=1). Regardless, to create a properly UTF-8 encoded file on Windows, use the `--output` option instead:\n\n```\n# so instead of redirecting stdout to a file\nqsv stats wcp.csv > wcpstats.csv\n\n# do this instead\nqsv stats wcp.csv --output wcpstats.csv\n```\n\n## Interpreters\nFor complex data-wrangling tasks, you can use Luau and Python scripts.\n### Luau\n\n[Luau](https://luau-lang.org) is a fast, small, safe, gradually typed, statically linked, embeddable scripting language derived from [Lua](https://www.lua.org/about.html). It lies at the [heart of Roblox technology](https://luau-lang.org/2022/11/04/luau-origins-and-evolution.html) - powering all it's user generated content, with [Roblox](https://en.wikipedia.org/wiki/Roblox)'s own internal code having more than 2 millions lines of Luau. \n\nIt has [sandboxing](https://luau-lang.org/sandbox), [type-checking](https://luau-lang.org/typecheck), [additional operators](https://luau-lang.org/syntax) & [increased performance](https://luau-lang.org/performance) while [maintaining compatibility with Lua](https://luau-lang.org/compatibility).\n\n[Lua is faster than Python](https://benchmarksgame-team.pages.debian.net/benchmarksgame/fastest/lua-python3.html) & Luau is even faster still - more so, as qsv precompiles Luau into bytecode. In addition, [`luau`](/src/cmd/luau.rs#L2) is embedded into qsv, has debug logging, can do aggregations with its `--begin` & `--end` options & has no external dependencies unlike the `py` command.\n\nIt also allows mapping of multiple new computed columns, supports random access with indexed CSV files, and has [several helper functions](https://github.com/jqnatividad/qsv/blob/c0c2d5ab3e4ea9cc0e861c6ad41652677ffc4f20/src/cmd/luau.rs#L1250-L1931) to help ease the development of [full-fledged data-wrangling scripts](https://github.com/jqnatividad/qsv/blob/4e521b177ea3a6a06c83222458bb1349a67606f4/tests/test_luau.rs#L524-L571).\n\nAs date manipulation is often needed, we're also preloading the [LuaDate](https://tieske.github.io/date/) module.\n\nFinally, as [qsv's DSL](#luau_deeplink) (üëë), `luau` will gain even more features over time compared to the `python` feature.\n\n[Luau 0.588](https://github.com/Roblox/luau/releases/tag/0.588) is currently embedded - qsv's policy is to use the latest stable Luau version at the time of each qsv release.\n\n### Python\n\nThe `python` feature is NOT enabled by default on the prebuilt binaries as its dynamically linked to python libraries at runtime, which presents distribution issues, as various operating systems have differing Python versions.\n\nIf you wish to enable the `python` feature - you'll just have to install/compile from source, making sure you have the development libraries for the desired Python version (Python 3.7 and above are supported) installed when doing so (e.g. on Debian/Ubuntu - `apt-get install python-dev`; on CentOS/RedHat/Amazon Linux - `yum install python-devel`; on Windows and macOS - use the [Python installer](https://www.python.org/downloads/) for the desired version).\n\nIf you plan to distribute your manually built `qsv` with the `python` feature, `qsv` will look for the specific version of Python shared libraries (libpython* on Linux/macOS, python*.dll on Windows) against which it was compiled starting with the current directory & abort with an error if not found, detailing the Python library it was looking for. \n\nNote that this will happen on qsv startup, even if you're NOT running the `py` command.\n\nWhen building from source - [PyO3](https://pyo3.rs) - the underlying crate that enables the `python` feature, uses a build script to determine the Python version & set the correct linker arguments. By default it uses the python3 executable.\nYou can override this by setting `PYO3_PYTHON` (e.g., `PYO3_PYTHON=python3.7`), before installing/compiling qsv. See the [PyO3 User Guide](https://pyo3.rs/v0.17.1/building_and_distribution.html) for more information.\n\nConsider using the [`luau`](/src/cmd/luau.rs#L2) command instead of the [`py`]((/src/cmd/python.rs#L2)) command if the operation you're trying to do can be done with `luau` - as `luau` is statically linked, has no external dependencies, much faster than `py`, can do aggregations, supports random access, has a bevy of qsv helper functions, and allows mapping of multiple new columns. \n\nThe `py` command cannot do aggregations because [PyO3's GIL-bound memory](https://pyo3.rs/v0.17.2/memory.html#gil-bound-memory) limitations will quickly consume a lot of memory (see [issue 449](https://github.com/jqnatividad/qsv/issues/449#issuecomment-1226095316) for details).\nTo prevent this, the `py` command processes CSVs in batches (default: 30,000 records), with a GIL pool for each batch, so no globals are available across batches.\n\n## Memory Management\nqsv supports three memory allocators - mimalloc (default), jemalloc and the standard allocator.<br>See [Memory Allocator](docs/PERFORMANCE.md#memory-allocator) for more info.\n\nIt also has Out-of-Memory prevention, with two modes - NORMAL (default) & CONSERVATIVE.<br>See [Out-of-Memory Prevention](docs/PERFORMANCE.md#out-of-memory-oom-prevention) for more info.\n\n## Environment Variables & dotenv file support\n\nqsv supports an extensive list of environment variables and supports `.env` files to set them.\n\nFor details, see [Environment Variables](docs/ENVIRONMENT_VARIABLES.md) and the [`dotenv.template.yaml`](dotenv.template.yaml) file.\n## Feature Flags\n\n`qsv` has several features:\n\n* `mimalloc` (default) - use the mimalloc allocator (see [Memory Allocator](docs/PERFORMANCE.md#memory-allocator) for more info).\n* `jemallocator` - use the jemalloc allocator (see [Memory Allocator](docs/PERFORMANCE.md#memory-allocator) for more info).\n* `apply` - enable `apply` command. This swiss-army knife of CSV transformations is very powerful, but it has a lot of dependencies that increases both compile time and binary size.\n* `fetch` - enables the `fetch` & `fetchpost` commands.\n* `foreach` - enable `foreach` command (not valid for Windows).\n* `generate` - enable `generate` command.\n* `luau` - enable `luau` command. Embeds a [Luau](https://luau-lang.org) interpreter into qsv. [Luau has type-checking, sandboxing, additional language operators, increased performance & other improvements](https://luau-lang.org/2022/11/04/luau-origins-and-evolution.html) over Lua.\n* `polars` - enables all [Polars](https://pola.rs)-powered commands (currently, `joinp` and `sqlp`). Note that Polars is a very powerful library, but it has a lot of dependencies that drastically increases both compile time and binary size.\n* `python` - enable `py` command. Note that qsv will look for the shared library for the Python version (Python 3.7 & above supported) it was compiled against & will abort on startup if the library is not found, even if you're NOT using the `py` command. Check [Python](#python) section for more info.\n* `to` - enables the `to` command. Note that enabling this feature will also noticeably increase both compile time and binary size.\n* `self_update` - enable self-update engine, checking GitHub for the latest release. Note that if you manually built qsv, `self-update` will only check for new releases.\nIt will NOT offer the choice to update itself to the prebuilt binaries published on GitHub. You need not worry that your manually built qsv will be overwritten by a self-update.\n\n* `feature_capable` - enable to build `qsv` binary variant which is feature-capable.\n* `all_features` - enable to build `qsv` binary variant with all features enabled (apply,fetch,foreach,generate,luau,polars,python,to,self_update).\n* `lite` - enable to build `qsvlite` binary variant with all features disabled.\n* `datapusher_plus` - enable to build `qsvdp` binary variant - the [DataPusher+](https://github.com/dathere/datapusher-plus) optimized qsv binary.\n* `nightly` - enable to turn on nightly/unstable features in the `rand`, `regex`, `hashbrown` & `pyo3` crates when building with Rust nightly/unstable.\n\n> ‚ÑπÔ∏è **NOTE:** `qsvlite`, as the name implies, always has **non-default features disabled**. `qsv` can be built with any combination of the above features using the cargo `--features` & `--no-default-features` flags. The prebuilt `qsv` binaries has **all applicable features valid for the target platform**[^2].\n\n## Minimum Supported Rust Version\n\nqsv's MSRV policy is to require the latest [Rust version](https://github.com/rust-lang/rust/blob/master/RELEASES.md) that is [supported by Homebrew](https://formulae.brew.sh/formula/rust#default), currently [![HomeBrew](https://img.shields.io/homebrew/v/rust?logo=homebrew)](https://formulae.brew.sh/formula/rust).\n\n## Tab Completion\n\nqsv's command-line options are quite extensive. Thankfully, since it uses [docopt](http://docopt.org/) for CLI processing,\nwe can take advantage of [docopt.rs' tab completion support](https://github.com/docopt/docopt.rs#tab-completion-support) to make it\neasier to use qsv at the command-line (currently, only bash shell is supported):\n\n```bash\n# install docopt-wordlist\ncargo install docopt\n\n# IMPORTANT: run these commands from the root directory of your qsv git repository\n# to setup bash qsv tab completion\necho \"DOCOPT_WORDLIST_BIN=\\\"$(which docopt-wordlist)\"\\\" >> $HOME/.bash_completion\necho \"source \\\"$(pwd)/scripts/docopt-wordlist.bash\\\"\" >> $HOME/.bash_completion\necho \"complete -F _docopt_wordlist_commands qsv\" >> $HOME/.bash_completion\n```\n\n## Testing\nqsv has ~1,170 tests in the [tests](https://github.com/jqnatividad/qsv/tree/master/tests) directory.\nEach command has its own test suite in a separate file with the convention `test_<COMMAND>.rs`.\nApart from preventing regressions, the tests also serve as good illustrative examples, and are often linked from the usage text of each corresponding command.\n\nTo test each binary variant:\n\n```bash\n# to test qsv\ncargo test --features all_features\n\n# to test qsvlite\ncargo test --features lite\n\n# to test qsvdp\ncargo test --features datapusher_plus,luau\n\n# to test a specific command\n# here we test only stats and use the\n# t alias for test and the -F shortcut for --features\ncargo t stats -F all_features\n```\n\n## License\n\nDual-licensed under MIT or the [UNLICENSE](https://unlicense.org).\n\n## Sponsor\n\n<div align=\"center\">\n\n|qsv was made possible by|\n:-------------------------:|\n|[![datHere Logo](docs/images/datHere-logo-withtagline.png)](https://datHere.com)<br>|\n|Standards-based, best-of-breed, open source solutions<br>to make your **Data Useful, Usable & Used.**   |\n\n</div>\n\n## Naming Collision\n\nThis project is unrelated to [Intel's Quick Sync Video](https://www.intel.com/content/www/us/en/architecture-and-technology/quick-sync-video/quick-sync-video-general.html)."
}
