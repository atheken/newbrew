{
  "name": "libvmaf",
  "full_name": "libvmaf",
  "tap": "homebrew/core",
  "oldname": null,
  "oldnames": [],
  "aliases": [],
  "versioned_formulae": [],
  "desc": "Perceptual video quality assessment based on multi-method fusion",
  "license": "BSD-2-Clause-Patent",
  "homepage": "https://github.com/Netflix/vmaf",
  "versions": {
    "stable": "2.3.1",
    "head": null,
    "bottle": true
  },
  "urls": {
    "stable": {
      "url": "https://github.com/Netflix/vmaf/archive/v2.3.1.tar.gz",
      "tag": null,
      "revision": null,
      "checksum": "8d60b1ddab043ada25ff11ced821da6e0c37fd7730dd81c24f1fc12be7293ef2"
    }
  },
  "revision": 0,
  "version_scheme": 0,
  "bottle": {
    "stable": {
      "rebuild": 0,
      "root_url": "https://ghcr.io/v2/homebrew/core",
      "files": {
        "arm64_ventura": {
          "cellar": ":any",
          "url": "https://ghcr.io/v2/homebrew/core/libvmaf/blobs/sha256:ddf330046166c9f25ad89679d04bc12375d3ad8b4454edeebb2e39667af53dce",
          "sha256": "ddf330046166c9f25ad89679d04bc12375d3ad8b4454edeebb2e39667af53dce"
        },
        "arm64_monterey": {
          "cellar": ":any",
          "url": "https://ghcr.io/v2/homebrew/core/libvmaf/blobs/sha256:780fe80d3941971968a0dfe1f8384fc5fc240e9994b09da41175a7d5fc56b513",
          "sha256": "780fe80d3941971968a0dfe1f8384fc5fc240e9994b09da41175a7d5fc56b513"
        },
        "arm64_big_sur": {
          "cellar": ":any",
          "url": "https://ghcr.io/v2/homebrew/core/libvmaf/blobs/sha256:76b4b46c07bde41001d5dd6660de656c369b1cf9653638538348e97ffaeec55f",
          "sha256": "76b4b46c07bde41001d5dd6660de656c369b1cf9653638538348e97ffaeec55f"
        },
        "ventura": {
          "cellar": ":any",
          "url": "https://ghcr.io/v2/homebrew/core/libvmaf/blobs/sha256:433acd17cf9b2bc4aca330fd9f27d32e2edbc62445df948fcf6030ec20fb47a4",
          "sha256": "433acd17cf9b2bc4aca330fd9f27d32e2edbc62445df948fcf6030ec20fb47a4"
        },
        "monterey": {
          "cellar": ":any",
          "url": "https://ghcr.io/v2/homebrew/core/libvmaf/blobs/sha256:a30aaf6bd5878809c3dec5f47d643e4adbda5811a13f5a20d21a3472d5151e2a",
          "sha256": "a30aaf6bd5878809c3dec5f47d643e4adbda5811a13f5a20d21a3472d5151e2a"
        },
        "big_sur": {
          "cellar": ":any",
          "url": "https://ghcr.io/v2/homebrew/core/libvmaf/blobs/sha256:60fb7784b39ae2aff9a836f08190637e9c7f2ac32755ed24ec3f5ddbac916c64",
          "sha256": "60fb7784b39ae2aff9a836f08190637e9c7f2ac32755ed24ec3f5ddbac916c64"
        },
        "catalina": {
          "cellar": ":any",
          "url": "https://ghcr.io/v2/homebrew/core/libvmaf/blobs/sha256:99db9a406ddacb8ca0c157dbea53eb12a29ced66091f2af820ae8bf9bc9802cd",
          "sha256": "99db9a406ddacb8ca0c157dbea53eb12a29ced66091f2af820ae8bf9bc9802cd"
        },
        "x86_64_linux": {
          "cellar": ":any_skip_relocation",
          "url": "https://ghcr.io/v2/homebrew/core/libvmaf/blobs/sha256:6697226f2c628ce462531ad546f8152b264f29151710cdb064659ac321cb92a4",
          "sha256": "6697226f2c628ce462531ad546f8152b264f29151710cdb064659ac321cb92a4"
        }
      }
    }
  },
  "keg_only": false,
  "keg_only_reason": null,
  "options": [],
  "build_dependencies": [
    "meson",
    "ninja",
    "nasm"
  ],
  "dependencies": [],
  "test_dependencies": [],
  "recommended_dependencies": [],
  "optional_dependencies": [],
  "uses_from_macos": [],
  "uses_from_macos_bounds": [],
  "requirements": [],
  "conflicts_with": [],
  "conflicts_with_reasons": [],
  "link_overwrite": [],
  "caveats": null,
  "installed": [],
  "linked_keg": null,
  "pinned": false,
  "outdated": false,
  "deprecated": false,
  "deprecation_date": null,
  "deprecation_reason": null,
  "disabled": false,
  "disable_date": null,
  "disable_reason": null,
  "post_install_defined": false,
  "service": null,
  "tap_git_head": "4eeae4ea50839e967536ba646d5e0ed6fbcbad7f",
  "ruby_source_path": "Formula/libvmaf.rb",
  "ruby_source_checksum": {
    "sha256": "68f1ed20d08b6655a203bc8ac276a85a18a758e35a7947046c9a034f73145d43"
  },
  "date_added": "2018-10-20T21:23:06+02:00",
  "readme": "# VMAF - Video Multi-Method Assessment Fusion\n\n[![Build Status](https://travis-ci.com/Netflix/vmaf.svg?branch=master)](https://travis-ci.com/Netflix/vmaf)\n[![libvmaf](https://github.com/Netflix/vmaf/workflows/libvmaf/badge.svg)](https://github.com/Netflix/vmaf/actions?query=workflow%3Alibvmaf)\n[![Windows](https://github.com/Netflix/vmaf/workflows/Windows/badge.svg)](https://github.com/Netflix/vmaf/actions?query=workflow%3AWindows)\n[![ffmpeg](https://github.com/Netflix/vmaf/workflows/ffmpeg/badge.svg)](https://github.com/Netflix/vmaf/actions?query=workflow%3Affmpeg)\n[![Docker](https://github.com/Netflix/vmaf/workflows/Docker/badge.svg)](https://github.com/Netflix/vmaf/actions?query=workflow%3ADocker)\n\nVMAF is an [Emmy-winning](https://theemmys.tv/) perceptual video quality assessment algorithm developed by Netflix. This software package includes a stand-alone C library `libvmaf` and its wrapping Python library. The Python library also provides a set of tools that allows a user to train and test a custom VMAF model.\n\nRead [this](https://medium.com/netflix-techblog/toward-a-practical-perceptual-video-quality-metric-653f208b9652) tech blog post for an overview, [this](https://medium.com/netflix-techblog/vmaf-the-journey-continues-44b51ee9ed12) post for the tips of best practices, and [this](https://netflixtechblog.com/toward-a-better-quality-metric-for-the-video-community-7ed94e752a30) post for our latest efforts on speed optimization, new API design and the introduction of a codec evaluation-friendly [NEG mode](resource/doc/models.md#disabling-enhancement-gain-neg-mode).\n\nAlso included in `libvmaf` are implementations of several other metrics: PSNR, PSNR-HVS, SSIM, MS-SSIM and CIEDE2000.\n\n![vmaf logo](resource/images/vmaf_logo.jpg)\n\n## News\n\n- (2021-12-15) We have added to CAMBI the `full_ref` input parameter to allow running CAMBI as a full-reference metric, taking into account the banding that was already present on the source. Check out the [usage](resource/doc/cambi.md) page.\n- (2021-12-1) We have added to CAMBI the `max_log_contrast` input parameter to allow to capture banding with higher contrasts than the default. We have also sped up CAMBI (e.g., around 4.5x for 4k). Check out the [usage](resource/doc/cambi.md) page.\n- (2021-10-7) We are open-sourcing CAMBI (Contrast Aware Multiscale Banding Index) - Netflix's detector for banding (aka contouring) artifacts. Check out the [tech blog](https://netflixtechblog.medium.com/cambi-a-banding-artifact-detector-96777ae12fe2) for an overview and the [technical paper](resource/doc/papers/CAMBI_PCS2021.pdf) published in PCS 2021 (note that the paper describes an initial version of CAMBI that no longer matches the code exactly, but it is still a good introduction). Also check out the [usage](resource/doc/cambi.md) page.\n- (2020-12-7) Check out our [latest tech blog](https://netflixtechblog.com/toward-a-better-quality-metric-for-the-video-community-7ed94e752a30) on speed optimization, new API design and the introduction of a codec evaluation-friendly NEG mode.\n- (2020-12-3) We are releasing `libvmaf v2.0.0`. It has a new fixed-point and x86 SIMD-optimized (AVX2, AVX-512) implementation that achieves 2x speed up compared to the previous floating-point version. It also has a [new API](libvmaf/README.md) that is more flexible and extensible.\n- (2020-7-13) We have created a [memo](https://docs.google.com/document/d/1dJczEhXO0MZjBSNyKmd3ARiCTdFVMNPBykH4_HMPoyY/edit?usp=sharing) to share our thoughts on VMAF's property in the presence of image enhancement operations, its impact on codec evaluation, and our solutions. Accordingly, we have added a new mode called [No Enhancement Gain (NEG)](resource/doc/models.md#disabling-enhancement-gain-neg-mode).\n- (2020-2-27) We have changed VMAF's license from Apache 2.0 to [BSD+Patent](https://opensource.org/licenses/BSDplusPatent), a more permissive license compared to Apache that also includes an express patent grant.\n\n## Documentation\n\nThere is an [overview of the documentation](resource/doc/index.md) with links to specific pages, covering FAQs, available models and features, software usage guides, and a list of resources.\n\n## Usage\n\nThe software package offers a number of ways to interact with the VMAF implementation.\n\n  - The command-line tool [`vmaf`](libvmaf/tools/README.md) provides a complete algorithm implementation, such that one can easily deploy VMAF in a production environment. Additionally, the `vmaf` tool provides a number of auxillary features such as PSNR, SSIM and MS-SSIM.\n  - The [C library `libvmaf`](libvmaf/README.md) provides an interface to incorporate VMAF into your code, and tools to integrate other feature extractors into the library.\n  - The [Python library](resource/doc/python.md) offers a full array of wrapper classes and scripts for software testing, VMAF model training and validation, dataset processing, data visualization, etc.\n  - VMAF is now included as a filter in FFmpeg, and can be configured using: `./configure --enable-libvmaf`. Refer to the [Using VMAF with FFmpeg](resource/doc/ffmpeg.md) page.\n  - [VMAF Dockerfile](Dockerfile) generates a docker image from the [Python library](resource/doc/python.md). Refer to [this](resource/doc/docker.md) document for detailed usage.\n  - To build VMAF on Windows, follow [these](resource/doc/windows.md) instructions.\n  - AOM CTC: [AOM]((http://aomedia.org/)) has specified vmaf to be the standard implementation metrics tool according to the AOM common test conditions (CTC). Refer to [this page](resource/doc/aom_ctc.md) for usage compliant with AOM CTC.\n\n## Contribution Guide\n\nRefer to the [contribution](CONTRIBUTING.md) page. Also refer to this [slide deck](https://docs.google.com/presentation/d/1Gr4-MvOXu9HUiH4nnqLGWupJYMeh6nl2MNz6Qy9153c/edit#slide=id.gc20398b4b7_0_132) for an overview contribution guide."
}
