{
  "name": "zpaqfranz",
  "full_name": "zpaqfranz",
  "tap": "homebrew/core",
  "oldname": null,
  "oldnames": [],
  "aliases": [],
  "versioned_formulae": [],
  "desc": "Deduplicating command-line archiver and backup tool",
  "license": "Public Domain and MIT and Zlib and Unlicense and BSD-2-Clause and Apache-2.0",
  "homepage": "https://github.com/fcorbelli/zpaqfranz",
  "versions": {
    "stable": "58.8",
    "head": "HEAD",
    "bottle": true
  },
  "urls": {
    "stable": {
      "url": "https://github.com/fcorbelli/zpaqfranz/archive/refs/tags/58.8.tar.gz",
      "tag": null,
      "revision": null,
      "checksum": "26e915a2c313675805714efed04a1082526ecbb02ea792c60b53e31d1a8bd402"
    },
    "head": {
      "url": "https://github.com/fcorbelli/zpaqfranz.git",
      "branch": "main"
    }
  },
  "revision": 0,
  "version_scheme": 0,
  "bottle": {
    "stable": {
      "rebuild": 0,
      "root_url": "https://ghcr.io/v2/homebrew/core",
      "files": {
        "arm64_ventura": {
          "cellar": ":any_skip_relocation",
          "url": "https://ghcr.io/v2/homebrew/core/zpaqfranz/blobs/sha256:3a86dca0e99ab05358c172347f3d5cb34f58c7a3724335354b43ef99c2c2b95a",
          "sha256": "3a86dca0e99ab05358c172347f3d5cb34f58c7a3724335354b43ef99c2c2b95a"
        },
        "arm64_monterey": {
          "cellar": ":any_skip_relocation",
          "url": "https://ghcr.io/v2/homebrew/core/zpaqfranz/blobs/sha256:e1d933af95c13fbf890c3fbacd7cfc982dca97b20487abf93ec1288ad3063778",
          "sha256": "e1d933af95c13fbf890c3fbacd7cfc982dca97b20487abf93ec1288ad3063778"
        },
        "arm64_big_sur": {
          "cellar": ":any_skip_relocation",
          "url": "https://ghcr.io/v2/homebrew/core/zpaqfranz/blobs/sha256:890f3045671e1768caf1a9dddfff37e16d22989942dfc88a5995b5b99d76ea48",
          "sha256": "890f3045671e1768caf1a9dddfff37e16d22989942dfc88a5995b5b99d76ea48"
        },
        "ventura": {
          "cellar": ":any_skip_relocation",
          "url": "https://ghcr.io/v2/homebrew/core/zpaqfranz/blobs/sha256:a8a01a3cc1bd092bc383463651ee4415e481d1df039fd0a4295b13f1db8bdf8e",
          "sha256": "a8a01a3cc1bd092bc383463651ee4415e481d1df039fd0a4295b13f1db8bdf8e"
        },
        "monterey": {
          "cellar": ":any_skip_relocation",
          "url": "https://ghcr.io/v2/homebrew/core/zpaqfranz/blobs/sha256:574908e466f82e099256209fcdc234947728c70118f12ebe957d3331f8060ce8",
          "sha256": "574908e466f82e099256209fcdc234947728c70118f12ebe957d3331f8060ce8"
        },
        "big_sur": {
          "cellar": ":any_skip_relocation",
          "url": "https://ghcr.io/v2/homebrew/core/zpaqfranz/blobs/sha256:380214bdde3dbdda8e750e610660addbb84a0d52ae13887f4d99888ef1a838fd",
          "sha256": "380214bdde3dbdda8e750e610660addbb84a0d52ae13887f4d99888ef1a838fd"
        },
        "x86_64_linux": {
          "cellar": ":any_skip_relocation",
          "url": "https://ghcr.io/v2/homebrew/core/zpaqfranz/blobs/sha256:28e1383aff696f1f89ad7b51073b8a045e73c5185e40954bba89a8e5c871e7ac",
          "sha256": "28e1383aff696f1f89ad7b51073b8a045e73c5185e40954bba89a8e5c871e7ac"
        }
      }
    }
  },
  "keg_only": false,
  "keg_only_reason": null,
  "options": [],
  "build_dependencies": [],
  "dependencies": [],
  "test_dependencies": [],
  "recommended_dependencies": [],
  "optional_dependencies": [],
  "uses_from_macos": [],
  "uses_from_macos_bounds": [],
  "requirements": [],
  "conflicts_with": [],
  "conflicts_with_reasons": [],
  "link_overwrite": [],
  "caveats": null,
  "installed": [],
  "linked_keg": null,
  "pinned": false,
  "outdated": false,
  "deprecated": false,
  "deprecation_date": null,
  "deprecation_reason": null,
  "disabled": false,
  "disable_date": null,
  "disable_reason": null,
  "post_install_defined": false,
  "service": null,
  "tap_git_head": "aa66a84309b297ea296f7a4b9c424b5c0ec4875c",
  "ruby_source_path": "Formula/zpaqfranz.rb",
  "ruby_source_checksum": {
    "sha256": "993bed3441afb870af7df48361220630edbd3e84cb25085b68dd3ed9c7e1c071"
  },
  "date_added": "2023-03-25T21:37:56-04:00",
  "readme": "# zpaqfranz: advanced multiplatform fork of ZPAQ 7.15, with SFX (on Windows), HW acceleration     \n\nSwiss army knife for backup and disaster recovery, like 7z or RAR on steroids,with deduplicated \"snapshots\" (versions). Conceptually similar to Mac time machine, but much more efficiently.  \n     \n###  Runs on: Windows 32/64, FreeBSD, OpenBSD, Linux, MacOS, Solaris, OmniOS, ESXi, QNAP-based NAS, Haiku OS\n\n.   \n[A freeware GUI (PAKKA) is available on Windows to make extraction easier](https://www.francocorbelli.it/pakka)\n_Please note: PAKKA is a Windows 32 EXE packed with mpress. Therefore it is possible that some antiviruses report false positives. I always recommend, as with any executable program, to take it only from reputable sources. It is actually the database backup portion of one of my ERP software, that's why I can't make an opensource version of it, it means rewriting from scratch. ***To avoid risks I put directly the download link from my personal site, the download is not logged.***_\n\n### [Wiki being written - be patient](https://github.com/fcorbelli/zpaqfranz/wiki)\n### [HELP](https://github.com/fcorbelli/zpaqfranz/wiki/HELP:-integrated)\n### [Binaries on sourceforge](https://sourceforge.net/projects/zpaqfranz/files/)  \n\n### OpenBSD: `pkg_add zpaqfranz`\n### FreeBSD: `pkg install zpaqfranz`\n### MacOS: `brew install zpaqfranz`\n\n## Classic archivers (tar, 7z, RAR etc) are obsolete, when used for repeated backups (daily etc), compared to the ZPAQ technology, that maintain \"snapshots\" (versions) of the data. [This is even more true in the case of ASCII dumps of databases (e.g. MySQL/MariaDB)](https://github.com/fcorbelli/zpaqfranz/wiki/Real-world:-SQL-dumps-(MySQL-MariaDB-Postgres-backup))\n\nLet's see.\nArchiving a folder multiple times (5), simulating a daily run Monday-to-Friday, with 7z\n\nhttps://user-images.githubusercontent.com/77727889/215149589-0f2d9f91-ea5a-4f60-b587-f2a506148fe9.mp4\n\nSame, but with zpaqfranz\n\nhttps://user-images.githubusercontent.com/77727889/215148702-edb8e5bb-8f4e-42bb-9637-6ee98742318a.mp4\n\n_As you can see, the .7z \"daily\" 5x backups takes ~ 5x the space of the .zpaq_\n\n![compare](https://user-images.githubusercontent.com/77727889/215150599-83032cc6-06b0-432d-ba3b-b410698e3631.jpg)\n\n## Seeing is believing (\"real world\")\n\nI thought it's best to show the difference for a more realistic example.  \n\nPhysical (small fileserver) Xeon machine with 8 cores, 64GB RAM and NVMe disks, plus Solaris-based NAS, 1Gb ethernet\n\nRsync update from filesystem to filesystem (real speed)  \n\nhttps://user-images.githubusercontent.com/77727889/215152167-c6ce107a-6345-4060-b7a7-33ad30b269ee.mp4\n\n\nRsync update to Solaris NAS (real speed)\n\nhttps://user-images.githubusercontent.com/77727889/215152259-2baa7001-d838-40de-b56c-6fe3feff9f1b.mp4\n\n\nBackup update from file system with zpaqfranz (real speed)  \n\nhttps://user-images.githubusercontent.com/77727889/215146670-1a11cd5d-6f00-4544-b797-9ca288ae12b1.mp4\n\nBackup upgrade via zfsbackup (real speed)\n\nhttps://user-images.githubusercontent.com/77727889/215147310-cc760f20-08b8-4088-9d8a-f58f00eac211.mp4\n\n# What?\n\nAt every run only data changed since the last execution will be added, creating a new version (the \"snapshot\").\nIt is then possible to restore the data @ the single version, just like snapshots by zfs or virtual machines, but a single-file level.  \n- Keeps a forever-to-ever copy (even thousands of versions), conceptually similar to Mac's time machine, but much more efficiently.  \n- Ideal for virtual machine disk storage (ex backup of vmdk), virtual disks (VHDx) and even TrueCrypt containers.  \n- Easily handles millions of files and tens of TBs of data.  \n- Allows rsync (or zfs replica) copies to the cloud with minimal data transfer and encryption.    \n- Multiple possibilities of data verification, fast, advanced and even paranoid.\n- Some optimizations for modern hardware (aka: SSD, NVMe, multithread).\n- By default triple-check with \"chunked\" SHA-1, XXHASH64 and CRC-32 (!).  \n\n```\nFor even higher level of paranoia, it is possible to use others hash algorithms, as\n```\n- MD5\n- SHA-1 of the full-file (NIST FIPS 180-4)\n- XXH3-128\n- BLAKE3 128\n- SHA-2-256 (NIST FIPS 180-4)\n- SHA-3-256 (NIST FIPS 202)\n- WHIRLPOOL (ISO/IEC 10118-3)\n- HIGHWAY (64,128,256)\n...And much more.  \n\n\n**No complex (and fragile) repository folders, with hundreds of \"whatever\", just only a single file!**  \n\n## Windows client? Minimum size (without software) VSS backups\n\n_It is often important to copy the %desktop% folder, Thunderbird's data, %download% and generally the data folders of a Windows system, leaving out the programs_\n\nReal speed (encrypted) update of C: without software (-frugal)  \n\nhttps://user-images.githubusercontent.com/77727889/215269540-8e2c8641-0d3a-4f67-a243-ab617834c5de.mp4\n\n## Are you a really paranoid Windows user (like me)? You can get sector-level copies of C:, too.\n\n_In this case the space used is obviously larger, as is the execution time, but even the \"most difficult\" folders are also taken. Deliberately the bitmap of occupied clusters is ignored: if you are paranoid, be all the way down!_  \n\n_It is just like a dd. You can't (for now) restore with zpaqfranz. You have to extract to a temporary folder and then use other software (e.g., 7z, OSFMount) to extract the files directly from the image_\n\nAccelerated speed (encrypted) every-sector update of a 256GB C: @ ~150MB/s\n\nhttps://user-images.githubusercontent.com/77727889/215271199-94400833-f973-41d2-a018-3f2277a648a9.mp4\n\n\n### To date, there is no software, free or paid, that matches this characteristics  \n_AFAIK of course_  \n10+ years of developing (2009-now).\n\n**Who did that?**\n\nOne of the world's leading scientists in compression.\n\n[No, not me, but this guy](http://mattmahoney.net/) [ZPAQ - Wikipedia](https://en.wikipedia.org/wiki/ZPAQ)\n\n**When?**\n\nFrom 2009 to 2016.\n\n**Where?**\n\nOn a Russian compression forum, one of the most famous, but obviously super-niche\n\n**Why is it not known as 7z or RAR, despite being enormously superior?**\n\nBecause lack of users who ... try it!\n\n**Who are you?**\n\nA user (and a developer) who has proposed and made various improvements that have been implemented over the years.\nWhen the author left the project, I made my fork to make the functions I need as a data storage manager.\n\n**Why is it no longer developed? Why should I use your fork?**\n\nBecause Dr. Mahoney is now retired and no longer supports it (he... run!)\n\n**Why should I trust? It will be one of 1000 other programs that silently fail and give problems**\n\nAs the Russians (and Italians) say, trust me, but check.\n\n**Archiving data requires safety. How can I be sure that I can then extract them without problems?**\n\nIt is precisely the portion of the program that I have evolved, implementing a barrage of controls up to the paranoid level, and more.\nLet's say there are verification mechanisms which you have probably never seen. Do you want to use SHA-2/SHA-3 to be very confident? You can.\n\nAccelerated speed of real world testing of archive >1GB/s\n\nhttps://user-images.githubusercontent.com/77727889/215271989-5a77e1f1-8fba-422b-9e25-24c3f4640eb2.mp4\n\n\n**ZPAQ (zpaqfranz) allows you to NEVER delete the data that is stored and will be available forever (in reality typically you starts from scratch every 1,000 or 2,000 versions, for speed reasons, on HDD. 10K+ on SSD), and restore the files present to each archived version, even if a month or three years ago.**\n\n\nReal-speed updating (on QNAP NAS) of a small server (300GB); ~7GB of Thunderbird mbox become ~6MB (!) in ~4 minutes. \n\nhttps://user-images.githubusercontent.com/77727889/215268613-e07e385c-0880-4534-ae35-0db8925cee6b.mp4\n\nIn this \"real world\" example (a ~500.000 files / ~500GB file server of a mid-sized enterprise), you will see 1042 \"snapshots\", stored in 877GB.\n\n```\nroot@f-server:/copia1/copiepaq/spaz2020 # zpaqfranz i fserver_condivisioni.zpaq\nzpaqfranz v51.27-experimental snapshot archiver, compiled May 26 2021\nfserver_condivisioni.zpaq:\n1042 versions, 1.538.727 files, 15.716.105 fragments, 877.457.003.477 bytes (817.20 GB)\nLong filenames (>255)     4.526\n\nVersion(s) enumerator\n-------------------------------------------------------------------------\n< Ver  > <  date  > < time >  < added > <removed>    <    bytes added   >\n-------------------------------------------------------------------------\n00000001 2018-01-09 16:56:02  +00308608 -00000000 ->      229.882.913.501\n00000002 2018-01-09 18:06:28  +00007039 -00000340 ->           47.356.864\n00000003 2018-01-10 15:06:25  +00007731 -00000159 ->            7.314.709\n00000004 2018-01-10 15:17:44  +00007006 -00000000 ->              612.584\n00000005 2018-01-10 15:47:03  +00007005 -00000000 ->              611.980\n00000006 2018-01-10 18:03:08  +00008135 -00000829 ->        2.698.417.427\n(...)\n00000011 2018-01-10 19:20:30  +00007007 -00000000 ->              613.273\n00000012 2018-01-11 07:00:36  +00007008 -00000000 ->              613.877\n(...)\n00000146 2018-03-27 17:08:39  +00001105 -00000541 ->          164.399.767\n00000147 2018-03-28 17:08:28  +00000422 -00000134 ->          277.237.055\n00000148 2018-03-29 17:12:02  +00011953 -00011515 ->          826.218.948\n(...)\n00001039 2021-05-02 17:17:42  +00030599 -00031135 ->       12.657.155.316\n00001040 2021-05-03 17:14:03  +00000960 -00000095 ->          398.358.496\n00001041 2021-05-04 17:13:40  +00000605 -00000004 ->           95.909.988\n00001042 2021-05-05 17:15:13  +00000579 -00000008 ->           82.487.415\n\n54.799 seconds (all OK)\n```\n\nDo you want to restore @ 2018-03-28?\n```\n00000147 2018-03-28 17:08:28  +00000422 -00000134 ->          277.237.055\n```\nVersion 147 =>\n```\nzpaqfranz x ... -until 147\n```\nDo you want 2021-03-05?\nVersion 984 =>\n```\nzpaqfranz x ... -until 984\n```\nAnother real world example: 4900 versions, from mid-2017\n```\nzpaqfranz v51.10-experimental journaling archiver, compiled Apr  5 2021\nfranz:use comment\nold_aserver.zpaq:\n\n4904 versions, 385.830 files, 3.515.679 fragments, 199.406.200.193 bytes (185.71\nGB)\n\nVersion comments enumerator\n------------\n00000001 2017-08-16 19:26:15  +00090863 -00000000 ->       79.321.339.869\n00000002 2017-08-17 13:29:25  +00000026 -00000000 ->              629.055\n00000003 2017-08-17 13:30:41  +00000005 -00000000 ->               18.103\n00000004 2017-08-17 14:34:12  +00000005 -00000000 ->               18.149\n00000005 2017-08-17 15:28:42  +00000008 -00000000 ->               99.062\n00000006 2017-08-17 19:30:03  +00000008 -00000000 ->            1.013.616\n00000007 2017-08-18 19:33:14  +00000021 -00000001 ->            2.556.335\n00000008 2017-08-19 19:29:23  +00000025 -00000000 ->            1.377.082\n00000009 2017-08-20 19:29:56  +00000002 -00000000 ->               24.153\n00000010 2017-08-21 19:34:35  +00000031 -00000000 ->            2.554.582\n(...)\n00004890 2021-02-16 16:40:51  +00000190 -00000005 ->           99.051.540\n00004891 2021-02-16 19:30:17  +00000065 -00000006 ->           16.467.364\n00004892 2021-02-17 19:34:04  +00000381 -00000257 ->           95.354.305\n(...)\n00004900 2021-02-25 19:35:47  +00000755 -00000611 ->          132.241.557\n00004901 2021-02-26 19:57:16  +00000406 -00000253 ->          122.669.868\n00004902 2021-02-27 20:33:45  +00000029 -00000002 ->           12.677.932\n00004903 2021-02-28 20:34:00  +00000027 -00000001 ->            6.978.088\n00004904 2021-03-01 20:33:52  +00000174 -00000019 ->           77.113.147\n```\n\nuntil 2021 (4 years later)\n\nThis is a ~200GB server\n```\n(...)\n- 2019-09-23 10:14:44       2.943.578.106  0666 /tank/mboxstorico/inviata_spazzatura__2017_2018\n- 2021-02-18 10:16:25           4.119.172  0666 /tank/mboxstorico/inviata_spazzatura__2017_2018.msf\n- 2019-10-25 15:39:15       1.574.715.392  0666 /tank/mboxstorico/nstmp\n- 2020-11-28 20:33:22           2.038.165  0666 /tank/mboxstorico/nstmp.msf\n- 2021-02-25 17:48:11               8.802  0644 /tank/mboxstorico/sha1.txt\n\n214.379.664.412 (199.66 GB) of 214.379.664.412 (199.66 GB) in 154.975 files shown\n```\nso for 4900 versions you need\n200GB*4900 = ~980TB with something like tar, 7z, RAR etc (yes, 980 terabytes),\nversus ~200GB (yes, 200GB) with zpaq.\n\nSame things for virtual machines (vmdks)\n\n## Why you say uniqueness? We got (hb) hashbackup, borg, restic, bupstash etc ##\n\nBecause other software (sometimes very, very good) runs on complex \"repositories\", very fragile and way too hard to manage (at least for my tastes).  \nIt may happen that you have to worry about backing up ... the backup, because maybe some files were lost during a transfer, corrupted etc.  \n_If it's simple, maybe it will work_\n\n## Too good to be true? ##\n\nObviously this is not \"magic\", it is simply the \"chaining\" of a block deduplicator with a compressor and an archiver.\nThere are faster compressors.\nThere are better compressors.\nThere are faster archivers.\nThere are more efficient deduplicators.\n\nBut what I have never found is a combination of these that is so simple to use and reliable, with excellent handling of non-Latin filenames (Chinese, Russian etc).\n\nThis is the key: you don't have to use complex \"pipe\" of tar | srep | zstd | something hoping that everything will runs file, but a single ~4MB executable, with 7z-like commands.  \nYou don't even have to install a complex program with many dependencies that will have to read a folder (the repository) with maybe thousands of files, hoping that they are all fully functional.\n\nThere are also many great features for backup, I mention only the greatest.  \n**The ZPAQ file is \"in addition\", it is never modified**\n\nSo rsync --append will copy only the portion actually added, for example on ssh tunnel to a remote server, or local NAS (QNAP etc) with tiny times.  \nTRANSLATION  \nYou can pay ~$4 a month for 1TB cloud-storage-space to store just about everything\n\nYou don't have to copy or synchronize let's say 700GB of tar.gz,7z or whatever, but only (say) the 2GB added in the last copy, the first 698GB are untouched.\n\nThis opens up the concrete possibility of using VDSL connections (upload ~ 2/4MB /s) to backup even virtual servers of hundreds of gigabytes in a few minutes.\n\nIn this (accelerated) video the rsync transfer of 2 remote backups: \"standard\" .zpaq archive (file level) AND zfsbackup (bit-level) for a small real-world server 1 day-update of work \n\nhttps://user-images.githubusercontent.com/77727889/215267855-22bf875c-90ee-47d1-8f8f-c2d0fa2ab201.mp4\n\n\n**Bonus: for a developer it's just like a \"super-git-versioning\"**\n\nIn the makefile just put at top a zpaq-save-everything and you will keep all the versions of your software, even with libraries, SQL dump etc.\nA single archive keeps everything, forever, with just one command (or two, for verify)\n    \n**Defects?**\n\nSome.\n\nThe main one is that the listing of files is not very fast, when there are many versions (thousands), due to the structure of the archiver-file-format. \n*I could get rid of it, but at the cost of breaking the backward compatibility of the file format, so I don't want to. On 52+ there is a workaround (-filelist)*\n\nIt is not the fastest tool out there, with real world performance of 80-200MB/s (depending on the case and HW of course).\n*Not a big deal for me (I have very powerful HW, and/or run nightly cron-tasks)*\n\nExtraction can require a number of seeks (due to various deduplicated blocks), which can slow down extraction on magnetic disks (but not on SSDs).  \n*If you have plenty of RAM now it is possible to bypass with the w command*\n\nNo other significant ones come to mind, except that it is known and used by few\n\n**Very hard to use?**  \nIt is a tool for power users and administrators, who are used to the command line. A text-based GUI is being developed to make data selection and complex extraction easier (!).  \n\nIn this example we want to extract all the .cpp files as .bak from the 1.zpaq archive. This is something you typically cannot do with other archives such as tar, 7z, rar etc.  \n### With a \"sort of\" WYSIWYG 'composer' \nFirst **f** key (find) and entering .cpp  \nThen **s** (search) every .cpp substring  \nThen **r** (replace) with .bak  \nThen **t** (to) for the z:\\example folder  \nFinally **x** to run the extraction  \n\nhttps://user-images.githubusercontent.com/77727889/226925740-d62b92ae-4eee-43ac-94a9-e1a6dae684c1.mp4\n\n\n**I do not trust you, but I am becoming curious. So?**\n\nOn **FreeBSD** [you can try to build the port (of paq, inside archivers)](https://www.freshports.org/archivers/paq) but it is very, very, very old (v 6.57 of 2014)  \nYou can get a \"not too old\" zpaqfranz with a `pkg install zpaqfranz`\n\nOn **OpenBSD** `pkg_add zpaqfranz` is usually rather updated\n\nOn **Debian** [there is a zpaq 7.15 package](https://packages.debian.org/sid/utils/zpaq)  \nYou can download the original version (7.15 of 2016) directly from the author's website, and compile it, or get the same from github.  \nIn this case be careful, because the source is divided into 3 source files, but nothing difficult for the compilation.  \n\n**OK, let's assume I want to try out zpaqfranz. How?**  \n\nFrom branch 51 all source code is merged in one zpaqfranz.cpp aiming to make it as easy as possible to compile on \"strange\" systems (NAS, vSphere etc).  \nUpdating, compilation and Makefile are now trivial.  \n\n# How to build\n\nMy main development platforms are INTEL Windows (non-Intel Windows (arm) currently unsupported) and FreeBSD.\n\nI rarely use Linux or MacOS or whatever (for compiling), so fixing may be needed.\n\nAs explained the program is single file, be careful to link the pthread library.  \nYou need it for ESXi too, even if it doesn't work. Don't be afraid, zpaqfranz knows!\n\n### Almost \"universal\" (minimal) Makefile.  \n_Beware to change /usr/local/bin to /bin on some *nix!_\n```\nCC?=            cc\nINSTALL?=       install\nRM?=            rm\nPROG=           zpaqfranz\nCFLAGS+=        -O3 -Dunix\nLDADD=          -pthread -lstdc++ -lm\nBINDIR=         /usr/local/bin\nBSD_INSTALL_PROGRAM?=   install -m 0555\n\nall:    build\n\nbuild:  ${PROG}\n\ninstall:        ${PROG}\n\t${BSD_INSTALL_PROGRAM} ${PROG} ${DESTDIR}${BINDIR}\n\n${PROG}:        ${OBJECTS}\n\t${CC}  ${CFLAGS} zpaqfranz.cpp -o ${PROG} ${LDADD}\nclean:\n\t${RM} -f ${PROG}\n```\n\nQuick and dirtier!\n```\nwget https://github.com/fcorbelli/zpaqfranz/raw/main/zpaqfranz.cpp\nwget https://github.com/fcorbelli/zpaqfranz/raw/main/NONWINDOWS/Makefile\nmake install clean\n```\n\nDirtiest (!) no SSL certificate (very old systems), get the nightly build\n```\nwget http://www.francocorbelli.it/zpaqfranz.cpp -O zpaqfranz.cpp\n```\n\nthen... build (aka: compile)\n\n\n_Library dependencies are minimal:   libc,libc++,libcxxrt,libm,libgcc_s,libthr_\n\nDEFINEs at compile-time\n```\n(nothing)                          // Compile for INTEL Windows\n-DHWBLAKE3 blake3_windows_gnu.S    // On Win64 enable HW accelerated BLAKE3 (with assembly)\n-DHWSHA1                           // On Win64 enable HW SHA1 (-hw)\n-DHWSHA2                           // Enable HW SHA2 (without assembly code to be linked)\n-Dunix                             // Compile on \"something different from Windows\"\n-DSOLARIS                          // Solaris is similar, but not equal, to BSD Unix\n-DNOJIT                            // By default zpaqfranz works on Intel CPUs\n                                   // (for simplicity I'll call them Intel, meaning x86-SSE2 and amd64)\n                                   // On non-Intel a -NOJIT should runs fine on LITTLE ENDIANs\n                                   // like Linux aarch64, Android aarch64 etc\n                                   // On BIG ENDIAN or \"strange things\" like middle endian \n                                   // (Honeywell 316) or little word (PDP-11)\n                                   // the autotest command is for you :)\n-DANCIENT                          // Turn off some functions for compiling in very old systems\n                                   // consuming less RAM (ex. PowerPC Mac), no auto C++\n-DBIG                              // Turn on BIG ENDIAN at compile time\n-DDEBUG                            // Old 7.15, almost useless. Use -debug switch instead\n-DESX                              // Yes, zpaqfranz run (kind of) on ESXi too :-)\n-DALIGNMALLOC                      // Force malloc to be aligned at something (sparc64)\n-DSERVER                           // Enable the cloudpaq client (for Windows)\n-DGUI                              // Enable the gui (ncurses on Windows)\n```\n\n### HIDDEN GEMS\nIf the (non Windows) executable is named \"dir\" act (just about)... like Windows' dir\nBeware of collisions with other software \"dir\".\n_It is way better than dir_\n\n### WARNINGS\nSome strange warnings with some compilers (too old, or too new), not MY fault\n\n### STRANGE THINGS\n\n_NOTE1: -, not -- (into switch)_\n\n_NOTE2: switches ARE case sensitive.   -maxsize <> -MAXSIZE_\n\n### THE JIT (just-in-time)\nzpaqfranz can translate ZPAQL opcodes into \"real\" Intel (amd64 or x86+SSE2) code, by default  \nOn other systems a **-DNOJIT** (arm CPUs for example) will enforce software interpration\n\n### SHA-1 HARDWARE ACCELERATION\nSome CPUs does have SHA instructions (typically AMD, not very widespread on Intel).  \nSo you can use a piece of 7-zip by Igor Pavlov (I am sure you know 7z) that is  \nnot really useful, but just for fun (faster BUT with higher latency).  \nFor performances reason, no run-time CPU compatibility checks, must be turn on   \nvia optional -hw switch  \nOn AMD 5950X runs ~1.86 GB/s vs ~951 MB/s  \nThe obj can be assembled from the fixed source code with asmc64  \nhttps://github.com/nidud/asmc  \nasmc64.exe sha1ugo.asm \nThen link the .obj and compile with -DHWSHA1  \nShort version:  not worth the effort for the GA release  \nFrom build 58+ there is a new -DHWSHA2, without linking of asm, that accelerate SHA256 too  \n\n### STATIC LINKING\nI like **-static** very much, there are a thousand arguments as to whether it is good or not. \nThere are strengths and weaknesses. \nNormally I prefer it, you do as you prefer.\n\n### TO BE NATIVE OR NOT TO BE?\nThe **-march=native**  is a switch that asks the compiler to activate all possible \noptimizations for the CPU on which zpaqfranz is being compiled. \nThis is to obtain the maximum possible performance, \nwhile binding the executable to the processor. \nIt should not be used if you intend, for some reason, \nto transfer the object program to a different system.\nIf you are compiling from source you can safely use it.\n\n### DEBIAN (and derivates)\nDebian does not \"like\" anything embedded https://wiki.debian.org/EmbeddedCopies\nzpaqfranz (on Windows) have two SFX modules (32 and 64)  \nand (every platform) a testfile (sha256.zpaq) for extraction autotest  \n(aka: weird CPUs)  \nIt is possible to make a Debian-package-compliant source code  \nwith some sed (or a single sed -e) (of course remove the |)\n```\nsed -i \"/DEBIAN|START/,/\\/\\/\\/DEBIA|NEND/d\"  zpaqfranz.cpp\nsed -i \"s/\\/\\/\\/char ext|ract_test1/char ext|ract_test1/g\" zpaqfranz.cpp\n```\n\n### Arch Linux\nI strongly advise against using zpaqfranz on this Linux distro(s).  \nThere is a bizarre policy on compiling executables.  \nObviously no one forbids it (**runs fine**), but just don't ask for help.  \n\n### TARGET EXAMPLES\n```\nWindows 64 (g++ 7.3.0)\ng++ -O3  zpaqfranz.cpp -o zpaqfranz \n\nWindows 64 (g++ 10.3.0) MSYS2\ng++ -O3  zpaqfranz.cpp -o zpaqfranz -pthread -static\n\nWindows 64 (g++, Hardware Blake3 implementation)\nIn this case, of course, linking the .S file is mandatory\ng++ -O3 -DHWBLAKE3 blake3_windows_gnu.S zpaqfranz.cpp -o zpaqfranz -pthread -static\n\nWindows 64 (g++, Hardware Blake3 implementation PLUS HW SHA1)\ng++ -O3 -DHWBLAKE3 -DHWSHA1 blake3_windows_gnu.s zpaqfranz.cpp sha1ugo.obj -o zpaqfranzhw -pthread -static\n\nWindows 64 (g++, Hardware Blake3 implementation PLUS HW SHA1/2 with GUI)\ng++ -O3 -DGUI -DHWBLAKE3 -DHWSHA2 blake3_windows_gnu.s zpaqfranz.cpp -o zpaqfranzhw -pthread -static -s\n\nWindows 32 (g++ 7.3.0 64 bit)\nc:\\mingw32\\bin\\g++ -m32 -O3 zpaqfranz.cpp -o zpaqfranz32 -pthread -static\n\nWindows 64 (g++ 7.3.0), WITH cloud paq\ng++ -O3 -DSERVER zpaqfranz.cpp -o zpaqfranz -lwsock32 -lws2_32\n\nFreeBSD (11.x) gcc 7\ngcc7 -O3 -Dunix zpaqfranz.cpp -lstdc++ -pthread -o zpaqfranz -static -lm\n\nFreeBSD (12.1) gcc 9.3.0\ng++ -O3 -Dunix zpaqfranz.cpp  -pthread -o zpaqfranz -static-libstdc++ -static-libgcc\n\nFreeBSD (11.4) gcc 10.2.0\ng++ -O3 -Dunix zpaqfranz.cpp  -pthread -o zpaqfranz -static-libstdc++ -static-libgcc -Wno-stringop-overflow\n\nFreeBSD (11.3) clang 6.0.0\nclang++ -Dunix zpaqfranz.cpp  -pthread -o zpaqfranz -static\n\nOpenBSD 6.6 clang++ 8.0.1\nOpenBSD 7.1 clang++ 13.0.0\nclang++ -Dunix -O3 zpaqfranz.cpp -o zpaqfranz -pthread -static\n\nDebian Linux (10/11) gcc 8.3.0\nubuntu 21.04 desktop-amd64 gcc  10.3.0\nmanjaro 21.07 gcc 11.1.0\ng++ -O3 -Dunix zpaqfranz.cpp  -pthread -o zpaqfranz -static\n\nQNAP NAS TS-431P3 (Annapurna AL314) gcc 7.4.0\ng++ -Dunix zpaqfranz.cpp  -pthread -o zpaqfranz -Wno-psabi\n\nFedora 34 gcc 11.2.1\nTypically you will need some library (out of a fresh Fedora box)\nsudo dnf install glibc-static libstdc++-static -y;\nThen you can compile, via Makefile or \"by hand\"\n(do not forget... sudo!)\n\nCentoOS\nPlease note:\n\"Red Hat discourages the use of static linking for security reasons. \nUse static linking only when necessary, especially against libraries provided by Red Hat. \"\nTherefore a -static linking is often a nightmare on CentOS => change the Makefile\ng++ -O3 -Dunix zpaqfranz.cpp  -pthread -o zpaqfranz\n\nSolaris 11.4 gcc 7.3.0\nOmniOS r151042 gcc 7.5.0\nBeware: -DSOLARIS and some different linking options\ng++ -O3 -DSOLARIS zpaqfranz.cpp -o zpaqfranz  -pthread -static-libgcc -lkstat\n\nMacOS 11.0 gcc (clang) 12.0.5, INTEL\nMacOS 12.6 gcc (clang) 13.1.6, INTEL\nPlease note:\nThe -std=c++11 is required, otherwise you have to change half a dozen lines (or -DANCIENT). \nNo -static here\n\"Apple does not support statically linked binaries on Mac OS X. \n(...) Rather, we strive to ensure binary \ncompatibility in each dynamically linked system library and framework\n(AHAHAHAHAHAH, note by me)\nWarning: Shipping a statically linked binary entails a significant compatibility risk. \nWe strongly recommend that you not do this...\"\nShort version: Apple does not like -static, so compile with\ng++ -Dunix  -O3  zpaqfranz.cpp -o zpaqfranz -pthread  \n\nMac PowerPC with gcc4.x\nLook at -DBIG (for BIG ENDIAN) and -DANCIENT (old-compiler)\ng++ -O3 -DBIG -DANCIENT -Dunix -DNOJIT zpaqfranz.cpp -o zpaqfranz -pthread\n\nApple Macintosh (M1/M2)\nUntested (yet), should be\ng++ -Dunix  -O3 -DNOJIT zpaqfranz.cpp -o zpaqfranz -pthread  -std=c++11\n\nESXi (gcc 3.4.6)\nNote: not fully developed ( extract() with minimum RAM need to be implemented )\ng++ -O3 -DESX zpaqfranz.cpp -o zpaqfranz6  -pthread -static -s\n\nsparc64 (not tested)\ntry\n-DALIGNMALLOC (+ other switches)\n\nHaiku R1/beta4, 64 bit (gcc 11.2.0), hrev56721\nNot very tested\ng++ -O3 -Dunix zpaqfranz.cpp -o zpaqfranz  -pthread -static\n\n\nBeware of #definitions\ng++ -dM -E - < /dev/null\nsometimes __sun, sometimes not\n```\n\n**Short help**\n```\nzpaqfranz h\n```\n\n\n**Long (full) help**\n```\nzpaqfranz h h\n```\n\n**Single help (a command or switch set)**\n```\n    zpaqfranz   h a   => ask help and examples for command 'a'\n    zpaqfranz -he a   => ask examples for command 'a'\n \n1on1       Delete folder2's files with same name/hash of folder1\na          Add or append files to archive\nautotest   Autotest for hidden errors after compiling from source\nb          CPU benchmark, speed index in (yes!) franzomips\nc          Compare one master dir against one or more slave dir(s)\ncp         Friendly file copy with ETA (resumable)\nd          Deduplicate files inside a single folder WITHOUT MERCY\ndir        A better dir (yes, Windows' dir)\ndirsize    Show cumulative folder(s) size\ne          Extract file(s) on current folder\nf          Free disk space fill (=reliability test) or wipe (privacy)\nfind       Search file(s) with wildcards\ng          Windows C: archiver from a shell without admin rights\ngui        Windows text-based GUI (listing-extraction)\ni          File (archive) information\nisopen     Check if a file isopen (by other software)\nk          Kill (delete) everything not in archive (RISKY!)\nl          List file(s)\nm          Merge (consolidate) multipart archive into one\nn          Decimate (keeping the newer X) older files\np          Paranoid test (slow, lot of RAM needed)\npassword   Change/remove password of single archive (no multipart)\npause      Halt script execution until time or keypress\nq          Windows archive of C: with VSS\nr          Robocopy one master to multiple slave folders\nrd         Remove hard-to-delete Windows' folder (ex. path too long)\nrsync      Delete rsync's dangling temporary files\ns          Get dir(s) size, return free disk space\nsfx        Create SFX module (with encryption support)\nsum        Calc hash/checksums, find duplicated files\nt          Test archive integrity\ntrim       Trim .zpaq archive from incomplete transaction\nutf        Convert filenames to latin, fix too long filenames etc\nv          Verify archive (against filesystem)\nversum     Hashdeep-like double check of hashes\nw          Chunked extraction/test of very big files\nx          Extract file(s)\nz          Remove empty directories\nfranz      Advanced switches\nmain       Most used switches\nnormal     Usual switches\nvoodoo     Nerd's switches\n```"
}
