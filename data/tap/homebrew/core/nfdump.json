{
  "name": "nfdump",
  "full_name": "nfdump",
  "tap": "homebrew/core",
  "oldname": null,
  "oldnames": [],
  "aliases": [],
  "versioned_formulae": [],
  "desc": "Tools to collect and process netflow data on the command-line",
  "license": "BSD-3-Clause",
  "homepage": "https://github.com/phaag/nfdump",
  "versions": {
    "stable": "1.7.2",
    "head": "HEAD",
    "bottle": true
  },
  "urls": {
    "stable": {
      "url": "https://github.com/phaag/nfdump/archive/v1.7.2.tar.gz",
      "tag": null,
      "revision": null,
      "checksum": "0545b792e81f5edd51a2fdfbfcc4eac7ba8087005811ab41c34bfac4d78fe926"
    },
    "head": {
      "url": "https://github.com/phaag/nfdump.git",
      "branch": "master"
    }
  },
  "revision": 0,
  "version_scheme": 0,
  "bottle": {
    "stable": {
      "rebuild": 0,
      "root_url": "https://ghcr.io/v2/homebrew/core",
      "files": {
        "arm64_ventura": {
          "cellar": "/opt/homebrew/Cellar",
          "url": "https://ghcr.io/v2/homebrew/core/nfdump/blobs/sha256:bcd7a9b774976dbb97d73fb1a93b36b7c5abc8579d7a303ccd78f86bd2fa7790",
          "sha256": "bcd7a9b774976dbb97d73fb1a93b36b7c5abc8579d7a303ccd78f86bd2fa7790"
        },
        "arm64_monterey": {
          "cellar": "/opt/homebrew/Cellar",
          "url": "https://ghcr.io/v2/homebrew/core/nfdump/blobs/sha256:40f2b32ea38db9b88c01d83ee1bcc6ff70528abd3e0097120a3396674d7e03ab",
          "sha256": "40f2b32ea38db9b88c01d83ee1bcc6ff70528abd3e0097120a3396674d7e03ab"
        },
        "arm64_big_sur": {
          "cellar": "/opt/homebrew/Cellar",
          "url": "https://ghcr.io/v2/homebrew/core/nfdump/blobs/sha256:3e25963361c30a566a9bc39b67d69621509685a8878e91e01c442fd6cd397479",
          "sha256": "3e25963361c30a566a9bc39b67d69621509685a8878e91e01c442fd6cd397479"
        },
        "ventura": {
          "cellar": "/usr/local/Cellar",
          "url": "https://ghcr.io/v2/homebrew/core/nfdump/blobs/sha256:10ef900bfcd6602875c14281ead4b3d6c7c745b775a748cfe3a9b692a3606dac",
          "sha256": "10ef900bfcd6602875c14281ead4b3d6c7c745b775a748cfe3a9b692a3606dac"
        },
        "monterey": {
          "cellar": "/usr/local/Cellar",
          "url": "https://ghcr.io/v2/homebrew/core/nfdump/blobs/sha256:11493b60f774efe3499cf527745f82761ee3eead78d9dc0d1af49a48ecf2bd70",
          "sha256": "11493b60f774efe3499cf527745f82761ee3eead78d9dc0d1af49a48ecf2bd70"
        },
        "big_sur": {
          "cellar": "/usr/local/Cellar",
          "url": "https://ghcr.io/v2/homebrew/core/nfdump/blobs/sha256:52933a62e14d28198597e492ae63dae43e5b32ee00fbbdf4981a8356afce9cc9",
          "sha256": "52933a62e14d28198597e492ae63dae43e5b32ee00fbbdf4981a8356afce9cc9"
        },
        "x86_64_linux": {
          "cellar": "/home/linuxbrew/.linuxbrew/Cellar",
          "url": "https://ghcr.io/v2/homebrew/core/nfdump/blobs/sha256:d848913d75859dd4811c2ae6e608a249a5d3872c23058113fb7ea1dfdbb64486",
          "sha256": "d848913d75859dd4811c2ae6e608a249a5d3872c23058113fb7ea1dfdbb64486"
        }
      }
    }
  },
  "keg_only": false,
  "keg_only_reason": null,
  "options": [],
  "build_dependencies": [
    "autoconf",
    "automake",
    "libtool",
    "pkg-config"
  ],
  "dependencies": [],
  "test_dependencies": [],
  "recommended_dependencies": [],
  "optional_dependencies": [],
  "uses_from_macos": [
    {
      "bison": "build"
    },
    {
      "flex": "build"
    },
    "bzip2",
    "libpcap"
  ],
  "uses_from_macos_bounds": [
    {},
    {},
    {},
    {}
  ],
  "requirements": [],
  "conflicts_with": [],
  "conflicts_with_reasons": [],
  "link_overwrite": [],
  "caveats": null,
  "installed": [],
  "linked_keg": null,
  "pinned": false,
  "outdated": false,
  "deprecated": false,
  "deprecation_date": null,
  "deprecation_reason": null,
  "disabled": false,
  "disable_date": null,
  "disable_reason": null,
  "post_install_defined": false,
  "service": null,
  "tap_git_head": "4eeae4ea50839e967536ba646d5e0ed6fbcbad7f",
  "ruby_source_path": "Formula/nfdump.rb",
  "ruby_source_checksum": {
    "sha256": "792b6febf3a3fdd4480b5862fab7644938439dbb749d278f21aa2265c299810d"
  },
  "date_added": "2015-04-24T18:22:29+01:00",
  "readme": "# nfdump\n\n[![buildtest](https://github.com/phaag/nfdump/actions/workflows/c-cpp.yml/badge.svg)](https://github.com/phaag/nfdump/actions/workflows/c-cpp.yml)\n\nnfdump-1.7.x or nfdump **unicorn** is the next release of nfdump.\n\n## Introduction\n\nnfdump is a toolset in order to collect and process netflow/ipfix and sflow data, sent from netflow/sflow compatible devices.\n\nThe toolset contains several collectors to collect flow data:\n\n- nfcapd supports netflow __v1__, __v5/v7__, __v9__ and __IPFIX__\n- sfcapd supports **sflow**. \n- nfpcapd converts pcap data read from a host interface or from pcap files.\n\nThe collected flow data is stored into files and can be process afterwards.\nnfdump processes and lists the flows in many different output formats and\ncan create a wide range of statistics.\n\n**nfdump** has a very powerful flow filter to process flows. The filter syn‐\ntax is very similar to tcpdump, but adapted and extended for flow filter‐\ning. A flow filter may also contain arrays of *many thousand IP addresses*\netc. to search for specific records.\n\n**nfdump** can aggreagte flows according to a user defined number of ele‐\nments. This masks certain elements and allows to sum up flow records\nmatching the same values.\n\nThe combination of flow *filtering* and *aggregation* as input for any flow\nstatistics allows **complex flow processing**. Pre‐filtered and aggregated\nflow data may also be written back into a binary flow file, which again\nmay be processed with nfdump\n\n**nfdump** can enrich the listing of flows with **geo location** information and\n**AS** information, unless AS information is already available in the flow\nrecords. IP addresses can be tagged with a two letter **country code**, or\nwith a longer location label containing the geographic region, country\nand city.  The geo location and AS information is retrieved from the\noptional **geoDB** database, created by the geolookup program from the nfdump\ntools.  geolookup uses the **Maxmind** database GeoDB or GeoLite2 to create a\nbinary lookup database for nfdump Please check the geolooup(1) man page\nfor more details.\n\nThere is also a [go-nfdump](https://github.com/phaag/go-nfdump) module to read nfdump flows files in Golang. \n\n### Compatibility\nnfdump-1.7.x is compatible to nfdump-1.6.18, which means it can read files \ncreated with nfdump-1.6.18 or newer. Flow files created with earlier nfdump\nversions may not contain all flow elements. If you have older files, it is\nrecommended to use nfdump-1.6.17 to update the records.\n\nNfdump 1.7.x provides the same set of programs as 1.6.x and can be used almost\nas a drop-in replacement. This may change in future and older legacy programs\nmay be removed. You can convert any old files from nfdump-1.6 to nfdump-1.7\nformat by reading/writing files: __./nfdump -r old-flowfile -y -w new-flowfile__\n\nPlease note, that only __nfdump__ may read older flow files. All other programs relay on the new file format.\n\nNote for NfSen users:  If you use NfSen, you must upgrade NfSen to the latest Github version https://github.com/phaag/nfsen. All specific binaries such as nfprofile and nftrack are still available with nfdump-1.7 but may be removed in future.\n\n### Improvements \n- nfdump is now a multi-threaded program and uses parallel threads mainly for\nreading, writing and processing flows as well as for sorting. This may result\nin faster flow processing, depending on the tasks. The speedimprovement \nalso heavily depends on the hardware (SSD/HD) and flow compression\noption. \n\n- For netflow v9 and IPFIX, nfdump now supports flexible length fields. This\nimproves compatibility with some exporters such as yaf and others.\n\n- Support for Cisco Network Based Application Recognition (NBAR).\n\n- Supports Maxmind geo location information to tag/geolocate IP addresses\n  and AS numbers.\n\n- nfpcapd automatically uses TPACKET_V3 for Linux or direct BPF sockets for\n  *BSD. This improves packet processing. It adds new options to collect MAC and\n  VLAN information if requested as well as the payload of the first packet. This\n  creates a lot of new possibilities in order to process and filter flows, such\n  as __nfdump -r flowfile 'payload content \"POST\"'__\n  nfpcapd can now store flow files locally or can sent them to a remote nfcapd\n  collector.\n\n- Metric exports: By default, every 60s a flow summary statistics  can be sent\n  to a UNIX socket. The corresponding program may be [nfinflux](https://github.com/phaag/nfinflux) to insert \n  these metrics into an influxDB or [nfexporter](https://github.com/phaag/nfexporter) for Prometheus monitoring.\n\n### New programs\nThe nfdump program suite has been extended by __geolookup__. It allows either\nto enrich IP addresses by country codes/locations and may add potential\nmissing AS information. Flows may be filtered according to country codes.\ngeolookup may also be used as standalone program to lookup IPs for AS/Geo\ninformation, similar to the famous Team Cymru whois service. geolookup uses a\nlocal database, which allows to process as many requests as you have.\nIn order to use geolookup, you need either a free or paid Maxmind account\nin order to convert the Maxmind .csv files into an nfdump vector data file. \n__geolookup__ needs to be enabled when running configure: __--enable-maxmind__\n\n---\n\n\n\n## NSEL/ASA, NEL/NAT support\n\n__NSEL__ (Network Event Security Logging) as well as NEL (NAT Event Logging) are technologies invented by __CISCO__ and also use the netflow v9 protocol. However, NSEL and NEL are not flows as commonly known but rather *__Events__!* exported from specific devices such as CISCO ASA. nfdump supports Event looging as part of netflow v9.\n\n__Jun OS NAT Event Logging__ is mostly compatible with CISCO's NAT Event Logging - mostly - it needs another data interpretation.\nSee __--enable-jnat__ below\n\n\n\n## Installation\n\n### Building and config options\n\nThe toolset is build upon the autotools framework. Run `./autogen.sh` first.\nAfterwards `./configure` `make` and `make install` should do the trick. \n\nFor various older Linuxes need a more modern compiler:\n\n#### CentOS 7.x:\n\n```c\n% yum install centos-release-scl\n```\n\nThen you can install GCC 8 and its C++ compiler:\n\n```c\n% yum install devtoolset-8-gcc devtoolset-8-gcc-c++\n```\n\nTo switch to a shell which defaults `gcc` and `g++` to this GCC version, use:\n\n```c\n% scl enable devtoolset-8 -- bash\n```\n\n#### Ubuntu 18.04 LTS:\n\n```c\n% sudo apt-get install clang-10\n% CC=clang-10 ./configure ...\n```\n\n\n\nThe following config options are available:\n\n* __--enable-sflow__  \nBuild sflow collector sfcapd; default is __NO__\n* __--enable-nfpcapd__  \nBuild nfpcapd collector to create netflow data from interface traffic or precollected pcap traffic; default is __NO__\n* __--enable-maxmind__  \nBuild geolookup program; default is __NO__\n*  __--enable-nsel__   \nCompile nfdump, to read and process NSEL/NEL event data; default is __NO__\n*  __--enable-jnat__   \nCompile nfdump, to read and process JunOS NAT event logging __NO__\n* __--with-zstdpath=PATH__\nExpect libzstd installed in **PATH**; default __/usr/local__\n* __--enable-ftconv__  \nBuild the flow-tools to nfdump converter; default is __NO__\n* __--enable-nfprofile__  \nBuild nfprofile used by NfSen; default is __NO__\n* __--enable-nftrack__  \nBuild nftrack used by PortTracker; default is __NO__\n\nDevelopment and beta options\n\n* __--enable-devel__  \nInsert lots of debug and development code into nfdump for testing and debugging; default is __NO__\n* __--enable-readpcap__  \nAdd code to nfcapd to read flow data also from pcap files; default is __NO__  \n\n### The tools\n__nfcapd__ - netflow collector daemon.  \nCollects the netflow data, sent from exporters and stores the flow records \ninto files.  Automatically rotates files every n minutes. ( typically \nevery 5 min ) The netflow versions mentioned above are read transparently\nMultiple netflow streams can be collected by a single or collector.  \nnfcapd can listen on IPv6 or IPv4. Furthermore multicast is supported.\n\n__nfdump__ - process collected netflow records.  \nNfdump reads the netflow data from one or many files stored by nfcapd. \nIt's filter syntax is similar to tcpdump ( pcap like ) but adapted for netflow.\nIf you like tcpdump you will like nfdump. nfdump displays netflow \ndata and/or creates top N statistics of flows, bytes, packets. nfdump \nhas a powerful and flexible flow aggregation including bi-directional \nflows. The output format is user selectable and also includes a simple \ncsv format for post processing.\n\n__nfanon__ - anonymize netflow records  \nIP addresses in flow records are anonimized using the CryptoPAn method.\n\n__nfexpire__ - expire old netflow data  \nManages data expiration. Sets appropriate limits. Used by NfSen.\n\n__nfreplay__ - netflow replay  \nReads the netflow data from the files stored by nfcapd and sends it\nover the network to another host.\n\n#### Optional binaries:\n\n__sfcapd__ - sflow collector daemon  \nscfapd collects sflow data and stores it into nfcapd compatible files.\n\"sfcapd includes sFlow(TM) code, freely available from https://github.com/sflow/sflowtool.\n\n__nfpcapd__ - pcap to netflow collector daemon  \nnfpcapd listens on a network interface, or reads precollected pcap traffic.\nIt either stores locally flow records into nfcapd compatible files or sends\nthe flows to a remote nfcapd collector. It is nfcapd's companion to convert\ntraffic directly into nfdump records.\n\n__geolookup__ - Geo location lookup program.\ngeolookup converts Maxmind's .csv files into the nfdump vector DB. The \nconverted DB may be used as a standalone lookup tool, or be be used by\nnfdump in order to automatically lookup country and location. \nPlease not: You need a legitimate Maxmind account (free or paid) in \norder to download the files.\n\n__ft2nfdump__ - flow-tools flow converter  \nft2nfdump converts flow-tools data into nfdump format. \n\n__nfprofile__ - netflow profiler. Required by NfSen  \nReads the netflow data from the files stored by nfcapd. Filters the \nnetflow data according to the specified filter sets ( profiles ) and\nstores the filtered data into files for later use. \n\n__nftrack__ - Port tracking decoder for NfSen plugin PortTracker.\n\n__nfreader__ - Framework for programmers  \nnfreader is a framework to read nfdump files for any other purpose.\nOwn C code can be added to process flows. nfreader is not installed\n\n#### Notes for sflow users:\nsfcapd and nfcapd can be used concurrently to collect netflow and sflow\ndata at the same time. Generic command line options apply to both \ncollectors likewise. sfcapd's sflow decoding module is based on InMon's \nsflowtool code and supports similar fields as nfcapd does for netflow v9, \nwhich is a subset of all available sflow fields in an sflow record. \nMore fields may be integrated in future versions of sfcapd.\n\n---\n\n### Compression\nBinary data files can optionally be compressed using either LZO1X-1, LZ4, ZSTD or bzip2 compression \nLZO is fastest but less efficient, LZ4 and ZSTD are fast and pretty efficient and bzip2 is slow but efficient. \n\nRecommendation: If you compress automatically flows while they are collected, use LZ4 **-z=lz4**\nas a standard. \n\nNotes: Bzip2 uses about 30 times more CPU than LZO1X-1. Use bzip2 to archive netflow\ndata, which may reduce the disk usage again by a factor of 2. The compression of flow files \ncan be changed any time with nfdump -J <algo[:level]>. You may also apply compression levels to lz4 and zstd such as **-z=zstd:9** or **-z=lz4:5** to improve efficiency at the cose of more CPU and slower compression speed. \n\nFor more details on each methde, see:\n\nLZO1X-1: http://www.oberhumer.com/opensource/lzo\n\nLZ4: https://github.com/lz4/lz4\n\nZSTD: https://github.com/facebook/zstd\n\nbzip2: http://www.bzip.org\n\n\n\n---\n\n## General Operation of nfdump\nThe goal of the design is to able to analyze netflow data from\nthe past as well as to track interesting traffic patterns \ncontinuously. The amount of time back in the past is limited only\nby the disk storage available for all the netflow data. The tools\nare optimized for speed for efficient filtering. The filter rules\nshould look familiar to the syntax of tcpdump ( pcap compatible ).\n\nAll data is stored to disk, before it gets analyzed. This separates\nthe process of storing and analyzing the data. \n\nThe data is organized in a time-based fashion. Every n minutes\n- typically 5 min - nfcapd rotates and renames the output file\nwith the timestamp nfcapd.YYYYMMddhhmm of the interval e.g. \nnfcapd.200907110845 contains data from July 11th 2009 08:45 onward.\nBased on a 5min time interval, this results in 288 files per day.\n\nAnalyzing the data can be done for a single file, or by concatenating\nseveral files for a single output. The output is either ASCII text\nor binary data, when saved into a file, ready to be processed again\nwith the same tools.\n\nYou may have several netflow sources - let's say 'router1' 'router2'\nand so on. The data is organized as follows:\n\n\t/flow_base_dir/router1\n\t/flow_base_dir/router2\n\nwhich means router1 and router2 are subdirs of the flow_base_dir.\n\nAlthough several flow sources can be sent to a single collector,\nIt's recommended to have multiple collector on busy networks for \neach source.\nExample: Start two collectors on different ports:\n\n\tnfcapd -D -S 2 -B 1024000 -w /flow_base_dir/router1 -p 23456\n\tnfcapd -D -S 2 -B 1024000 -w /flow_base_dir/router2 -p 23457\n\nnfcapd can handle multiple flow sources.\nAll sources can go into a single file or can be split:\n\nAll into the same file:\n\n\tnfcapd -D -S 2 -w /flow_base_dir/routers -p 23456\n\nCollected on one port and split per source:\n\n\tnfcapd -D -S 2 -n router1,172.16.17.18,/flow_base_dir/router1 \\\n\t\t-n router2,172.16.17.20,/flow_base_dir/router2 -p 23456\n\nSee nfcapd(1) for a detailed explanation of all options.\n\nSecurity: none of the tools requires root privileges, unless you have\na port < 1024. However, there is no access control mechanism in nfcapd.\nIt is assumed, that host level security is in place to filter the \nproper IP addresses.\n\nSee the manual pages or use the -h switch for details on using each of \nthe programs. For any questions send email to peter@people.ops-trust.net\n\nConfigure your router to export netflow. See the relevant documentation\nfor your model. \n\nA generic Cisco sample configuration enabling NetFlow on an interface:\n\n    ip address 192.168.92.162 255.255.255.224\n     interface fastethernet 0/0\n     ip route-cache flow\n\nTo tell the router where to send the NetFlow data, enter the following \nglobal configuration command:\n\n\tip flow-export 192.168.92.218 9995\n\tip flow-export version 5 \n\t\n\tip flow-cache timeout active 5\n\nThis breaks up long-lived flows into 5-minute segments. You can choose \nany number of minutes between 1 and 60;\n\n\nNetflow v9 full export example of a cisco 7200 with sampling enabled:\n\n    interface Ethernet1/0\n     ip address 192.168.92.162 255.255.255.224\n     duplex half\n     flow-sampler my-map\n    !\n    !\n    flow-sampler-map my-map\n     mode random one-out-of 5\n    !\n    ip flow-cache timeout inactive 60\n    ip flow-cache timeout active 1\n    ip flow-capture fragment-offset\n    ip flow-capture packet-length\n    ip flow-capture ttl\n    ip flow-capture vlan-id\n    ip flow-capture icmp\n    ip flow-capture ip-id\n    ip flow-capture mac-addresses\n    ip flow-export version 9\n    ip flow-export template options export-stats\n    ip flow-export template options sampler\n    ip flow-export template options timeout-rate 1\n    ip flow-export template timeout-rate 1\n    ip flow-export destination 192.168.92.218 9995\n\n\nSee the relevant documentation for a full description of netflow commands\n\nNote: Netflow version v5 and v7 have 32 bit counter values. The number of\npackets or bytes may overflow this value, within the flow-cache timeout\non very busy routers. To prevent overflow, you may consider to reduce the \nflow-cache timeout to lower values. All nfdump tools use 64 bit counters \ninternally, which means, all aggregated values are correctly reported.\n\nThe binary format of the data files is netflow version independent.\nFor speed reasons the binary format is machine architecture dependent, and \nas such can not be exchanged between little and big endian systems.\nInternally nfdump does all processing IP protocol independent, which means\neverything works for IPv4 as well as IPv6 addresses.\nSee the nfdump(1) man page for details. \n\nnetflow version 9 and infix:\nnfcapd supports a large range of netflow v9 and ipfix tags. Version 1.7 of nfdump \nalso supports FNF - flexible netflow, subtemplates and understands a few specific exporters such as **yaf**.\n\n### sfcpad\n\nThis collector collects sflow https://www.sflow.org exports. It is largely identical to nfcapd except it only understands sflow packets. \n\n### nfpcapd\n\nThis collector is able to listen on a host interface and generates netflow data from the network data stream on that interface. It make use of **PACKET_RX_RING** to read packets on an interface device level (**TPACKETV3**) on Linux hosts or of the **BPF** interface - Berkeley Packet Filter on ***BSD** hosts which provides raw access to data link layers. Nfpcapd builds an internal netflow cache which is periodically written to disk or forwarded to an nfcapd server. As a special feature, nfpcpad may collect the first few bytes of a network connection, if requested to do so ( **-o payload**), which allows filter and evaluate the flows with nfdump later. \n\nListen on eth0 and store the flows locally. Set flow cache active timeout to 60s, inactive tiemout to 30s: \n\n```\nnfpcapd -D -S 2 -w /var/flows -i eth0 -e 60,30 -u daemon -g daemon\n```\n\nListen on eth0 and forward flow data to nfcapd running on a remote host. Add tunnel infos, MAC addr, vlan labels and first packet payload to the flows:\n\n```\nnfpcapd -D -S 2 -H 192.168.168.40 -i eth0 -e 60,30 -o fat,payload -u daemon -g daemon\n```\n\nIn order to evaluate the payload, nfdump has some rudimentory payload decoder for DNS, ja3, ja3s and a few other.\n\nAlternatively nfpcapd can also convert existing cap files into flow data:\n\n```\nnfpcapd -S 2 -w /var/flows -r pcapfile.pcap -e 60,30 -o fat,payload\n```\n\n\n\n---\n\n### Flowset record types\n\nLinks\n\nExtensions: nfcapd supports a large number of v9 tags. It automatically add\nextensions to store data for v9/IPFIX elements which are supported.\n\n### Sampling\nBy default, the sampling rate is set to 1 (unsampled) or to any given value specified \nby the **-s** cmd line option. If sampling information is found in the netflow stream, \nit overwrites the default value. Sampling is automatically recognised when announced \nin v9/ipfix option templates with tags set (**#302, #304, #305, #306**),  ( **#48, #49, #50** ), ( **#34, #35**)or in the unofficial v5 header hack. The sampling data is stored in the sampling **PacketInterval/PacketSpace** model. If announced differently, it is converted accordingly.\n\nNote: Not all platforms (or vendor software versions) support exporting sampling information\nin netflow data, even if sampling is configured. The number of bytes/packets in each \nnetflow record is automatically multiplied by the sampling rate. The total number of \nflows is not changed as this is not accurate enough. (Small flows versus large flows)\n\nFor more information, see the GitHub Wiki.\n\nIf you like this project your company may consider sponsoring it :) https://github.com/sponsors/phaag"
}
